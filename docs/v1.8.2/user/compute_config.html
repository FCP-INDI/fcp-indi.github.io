
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Computer Settings &#8212; C-PAC 1.8.2.dev Beta documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/classic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    
    <link rel="index" title="Index" href="../genindex" />
    <link rel="search" title="Search" href="../search" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index">C-PAC 1.8.2.dev Beta documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Computer Settings</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="computer-settings">
<h1>Computer Settings<a class="headerlink" href="#computer-settings" title="Permalink to this headline">¶</a></h1>
<figure class="align-default">
<img alt="../_images/compute_gui.png" src="../_images/compute_gui.png" />
</figure>
<p><strong>Pipeline Name - [text]:</strong> Name for this pipeline configuration - useful for identification.  <em>Note that including an individual participant’s ID code in this will presently cause C-PAC to crash.</em></p>
<ol class="arabic simple">
<li><p><strong>Maximum Memory Per Participant (GB) - [number]:</strong>  The maximum amount of memory each participant’s workflow can allocate. Use this to place an upper bound of memory usage. <strong>Warning: ‘Memory Per Participant’ multiplied by ‘Number of Participants to Run Simultaneously’ must not be more than the total amount of RAM. Conversely, using too little RAM can impede the speed of a pipeline run. It is recommended that you set this to a value that when multiplied by ‘Number of Participants to Run Simultaneously’ is as much RAM you can safely allocate.</strong></p></li>
<li><p><strong>Maximum Cores Per Participant - [integer]:</strong> Number of cores (on a single machine) or slots on a node (cluster/grid) per subject. Slots are cores on a cluster/grid node. ‘Number of Cores Per Participant’ multiplied by ‘Number of Participants to Run Simultaneously’ must not be greater than the total number of cores. Dedicating more than one core/CPU per participant will direct C-PAC to parallelize the motion correction and time series registration transform application steps, for a speed increase.</p></li>
<li><p><strong>Number of Participants to Run Simultaneously - [integer]:</strong> This number depends on computing resources.</p></li>
<li><p><strong>Number of Cores for Anatomical Registration (ANTS) - [integer]:</strong> This number depends on computing resources.</p></li>
<li><p><strong>FSL directory - [path]:</strong> Full path to the FSL version to be used by CPAC. If you have specified an FSL path in your .bashrc file, this path will be set automatically.</p></li>
<li><p><strong>Run CPAC on a Cluster/Grid - [False, True]:</strong> Select False if you intend to run CPAC on a single machine. If set to True, CPAC will attempt to submit jobs through the job scheduler / resource manager selected below.</p></li>
<li><p><strong>Resource Manager - [SGE, PBS, SLURM]:</strong> Sun Grid Engine (SGE), Portable Batch System (PBS) or Slurm. Only applies if you are running on a grid or compute cluster.  See the section below entitled <cite>SGE Configuration</cite> for more information on how to set up SGE.</p></li>
<li><p><strong>SGE Parallel Environment - [text]:</strong> SGE Parallel Environment to use when running CPAC. Only applies when you are running on a grid or compute cluster using SGE.  See the section below entitled <cite>SGE Configuration</cite> for more information on how to set up SGE.</p></li>
<li><p><strong>SGE Queue - [text]:</strong> SGE Queue to use when running CPAC. Only applies when you are running on a grid or compute cluster using SGE.  See the section below entitled <cite>SGE Configuration</cite> for more information on how to set up SGE.</p></li>
</ol>
<section id="configuration-without-the-gui">
<h2>Configuration Without the GUI<a class="headerlink" href="#configuration-without-the-gui" title="Permalink to this headline">¶</a></h2>
<p>The following nested key/value pairs will be set to these defaults if not defined in your <a class="reference internal" href="pipelines/pipeline_config"><span class="doc">pipeline configuration YAML</span></a>.</p>
<div class="highlight-YAML notranslate"><div class="highlight"><pre><span></span><span class="nt">pipeline_setup</span><span class="p">:</span>
</pre></div>
</div>
<div class="highlight-YAML notranslate"><div class="highlight"><pre><span></span>  <span class="nt">system_config</span><span class="p">:</span>

    <span class="c1"># Select Off if you intend to run CPAC on a single machine.</span>
    <span class="c1"># If set to On, CPAC will attempt to submit jobs through the job scheduler / resource manager selected below.</span>
    <span class="nt">on_grid</span><span class="p">:</span>

      <span class="nt">run</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Off</span>

      <span class="c1"># Sun Grid Engine (SGE), Portable Batch System (PBS), or Simple Linux Utility for Resource Management (SLURM).</span>
      <span class="c1"># Only applies if you are running on a grid or compute cluster.</span>
      <span class="nt">resource_manager</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">SGE</span>

      <span class="nt">SGE</span><span class="p">:</span>
        <span class="c1"># SGE Parallel Environment to use when running CPAC.</span>
        <span class="c1"># Only applies when you are running on a grid or compute cluster using SGE.</span>
        <span class="nt">parallel_environment</span><span class="p">:</span>  <span class="l l-Scalar l-Scalar-Plain">mpi_smp</span>

        <span class="c1"># SGE Queue to use when running CPAC.</span>
        <span class="c1"># Only applies when you are running on a grid or compute cluster using SGE.</span>
        <span class="nt">queue</span><span class="p">:</span>  <span class="l l-Scalar l-Scalar-Plain">all.q</span>

    <span class="c1"># The maximum amount of memory each participant&#39;s workflow can allocate.</span>
    <span class="c1"># Use this to place an upper bound of memory usage.</span>
    <span class="c1"># - Warning: &#39;Memory Per Participant&#39; multiplied by &#39;Number of Participants to Run Simultaneously&#39;</span>
    <span class="c1">#   must not be more than the total amount of RAM.</span>
    <span class="c1"># - Conversely, using too little RAM can impede the speed of a pipeline run.</span>
    <span class="c1"># - It is recommended that you set this to a value that when multiplied by</span>
    <span class="c1">#   &#39;Number of Participants to Run Simultaneously&#39; is as much RAM you can safely allocate.</span>
    <span class="nt">maximum_memory_per_participant</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>

    <span class="c1"># The maximum amount of cores (on a single machine) or slots on a node (on a cluster/grid)</span>
    <span class="c1"># to allocate per participant.</span>
    <span class="c1"># - Setting this above 1 will parallelize each participant&#39;s workflow where possible.</span>
    <span class="c1">#   If you wish to dedicate multiple cores to ANTS-based anatomical registration (below),</span>
    <span class="c1">#   this value must be equal or higher than the amount of cores provided to ANTS.</span>
    <span class="c1"># - The maximum number of cores your run can possibly employ will be this setting multiplied</span>
    <span class="c1">#   by the number of participants set to run in parallel (the &#39;Number of Participants to Run</span>
    <span class="c1">#   Simultaneously&#39; setting).</span>
    <span class="nt">max_cores_per_participant</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>

    <span class="c1"># The number of cores to allocate to ANTS-based anatomical registration per participant.</span>
    <span class="c1"># - Multiple cores can greatly speed up this preprocessing step.</span>
    <span class="c1"># - This number cannot be greater than the number of cores per participant.</span>
    <span class="nt">num_ants_threads</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>

    <span class="c1"># The number of cores to allocate to processes that use OpenMP.</span>
    <span class="nt">num_OMP_threads</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>

    <span class="c1"># The number of participant workflows to run at the same time.</span>
    <span class="c1"># - The maximum number of cores your run can possibly employ will be this setting</span>
    <span class="c1">#   multiplied by the number of cores dedicated to each participant (the &#39;Maximum Number of Cores Per Participant&#39; setting).</span>
    <span class="nt">num_participants_at_once</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>

    <span class="c1"># Full path to the FSL version to be used by CPAC.</span>
    <span class="c1"># If you have specified an FSL path in your .bashrc file, this path will be set automatically.</span>
    <span class="nt">FSLDIR</span><span class="p">:</span>  <span class="l l-Scalar l-Scalar-Plain">/usr/share/fsl/5.0</span>
</pre></div>
</div>
</section>
<section id="setting-up-sge">
<h2>Setting up SGE<a class="headerlink" href="#setting-up-sge" title="Permalink to this headline">¶</a></h2>
<section id="preliminaries">
<h3>Preliminaries<a class="headerlink" href="#preliminaries" title="Permalink to this headline">¶</a></h3>
<p>Before you configure Sun Grid Engine so that it works with C-PAC, you should understand the following concepts:</p>
<ul class="simple">
<li><p><strong>Job Scheduler</strong> - A program that can allocate computational resources in an HPC cluster to jobs based on availability and distribute jobs across nodes. C-PAC can use Sun Grid Engine (SGE) as its job scheduler (and SGE comes pre-configured with C-PAC’s <cite>cloud image &lt;cloud&gt;</cite>).</p></li>
<li><p><strong>Parallel Environment</strong> - A specification for how SGE parallelizes work.  Parallel environments can have limits on the number of CPUs used, whitelists and blacklists that dictate who can use resources, and specific methods for balancing server load during distributed tasks.</p></li>
<li><p><strong>The Job Queue</strong> - A grouping of jobs that run at the same time.  The queue can be frozen, in which case all jobs that it contains will cease.</p></li>
<li><p><strong>Head Node</strong> - The primary node of an HPC cluster, to which all other nodes are connected.  The head node will run a job scheduler (such as Sun Grid Engine) to allocate jobs to the other nodes.</p></li>
<li><p><strong>Worker Node</strong> - A node in an HPC cluster to which tasks are delegated by the head node via a job scheduler.</p></li>
<li><p><strong>Job Submission Script</strong> - A shell script with a series of commands to be executed as part of the job.  Submission scripts may also include flags that activate functionality specific to the scheduler.</p></li>
</ul>
</section>
<section id="configuring-a-parallel-environment">
<h3>Configuring A Parallel Environment<a class="headerlink" href="#configuring-a-parallel-environment" title="Permalink to this headline">¶</a></h3>
<p>The specifics of configuring a parallel environment in SGE more broadly are beyond the scope of this guide (see <a class="reference external" href="https://blogs.oracle.com/templedf/entry/configuring_a_new_parallel_environment">Oracle’s blog</a> for a good primer).  Nevertheless, we will discuss how to configure an environment that is compatible with C-PAC.  To do this, we will first create a file named <em>mpi_smp.conf</em> that will appear as follows:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">pe_name            mpi_smp</span>
<span class="go">slots              999</span>
<span class="go">user_lists         NONE</span>
<span class="go">xuser_lists        NONE</span>
<span class="go">start_proc_args    NONE</span>
<span class="go">stop_proc_args     NONE</span>
<span class="go">allocation_rule    $pe_slots</span>
<span class="go">control_slaves     TRUE</span>
<span class="go">job_is_first_task  FALSE</span>
<span class="go">urgency_slots      min</span>
<span class="go">accounting_summary TRUE</span>
</pre></div>
</div>
<p>This configuration ensures that:</p>
<ul class="simple">
<li><p>All of the cores will be used (assuming your system has fewer than 999 cores; if you are lucky enough to have more than this, the maximum value for this field is 9999999).</p></li>
<li><p>No users are whitelisted or blacklisted and no special hooks or cleanup tasks occur before or after a job.</p></li>
<li><p>All job slots that a C-PAC job submission requests are on the same machine (this ensures that each unique subject’s computations are taken care of by the same node and the cores allocated for one of C-PAC’s steps are not distributed across different machines).</p></li>
<li><p>SGE has full control over the jobs submitted (in terms of resource scheduling).</p></li>
<li><p>The C-PAC run is not part of a parallel job that would require an awareness of which task was performed first (the subjects can be assigned to nodes in any order).</p></li>
<li><p>An accounting record is written concerning how the job used resources.</p></li>
</ul>
<p>To activate this parallel environment and tie it to a job queue named <em>all.q</em>, execute the following commands on your cluster’s master node:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">qconf -Ap /path/to/mpi_smp.conf</span>
<span class="go">qconf -mattr queue pe_list &quot;mpi_smp&quot; all.q</span>
</pre></div>
</div>
<p>You would then set the SGE Parallel Environment to <em>mpi_smp</em> and the SGE queue to <em>all.q</em> in your pipeline configuration file before starting your C-PAC run.</p>
</section>
</section>
<section id="additional-links">
<h2>Additional Links<a class="headerlink" href="#additional-links" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="http://www.csb.yale.edu/userguides/sysresource/batch/doc/UserGuide_6.1.pdf">The Sun Grid Engine User Guide</a></p></li>
<li><p><a class="reference external" href="http://star.mit.edu/cluster/docs/0.93.3/guides/sge.html">Starcluster’s Sun Grid Engine Tutorial</a></p></li>
<li><p><a class="reference external" href="https://blogs.oracle.com/templedf/entry/configuring_a_new_parallel_environment">Oracle’s Parallel Environment Tutorial</a></p></li>
<li><p><a class="reference external" href="https://newton.utk.edu/doc/Documentation/UsingTheGridEngine/">University of Tennessee Knoxville’s Guide to Using SGE</a></p></li>
</ul>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index">
              <img class="logo" src="../_static/cpac_logo_vertical.png" alt="Logo"/>
            </a></p>
  <h3><a href="../index">Table of Contents</a></h3>
  <ul>
<li class="toctree-l1"><a class="reference internal" href="index">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer/index">Welcome to CPAC’s developer documentation!</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer/index#indices-and-tables">Indices and tables</a></li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index">C-PAC 1.8.2.dev Beta documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Computer Settings</a></li> 
      </ul>
    </div>

    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, C-PAC Team.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.3.1.
    </div>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-19224662-10"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-19224662-10');
    </script>
    <script defer src="https://fcp-indi.github.io/scripts/versionList.js"></script>

  </body>
</html>