
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Running C-PAC &#8212; C-PAC 1.8.5.dev1 Beta documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/classic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex" />
    <link rel="search" title="Search" href="../search" />
    <link rel="next" title="Group-Level Analysis" href="group_analysis" />
    <link rel="prev" title="Computable Derivatives" href="derivatives" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="group_analysis" title="Group-Level Analysis"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="derivatives" title="Computable Derivatives"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index">C-PAC 1.8.5.dev1 Beta documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index" accesskey="U">User Documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Running C-PAC</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="running-c-pac">
<h1>Running C-PAC<a class="headerlink" href="#running-c-pac" title="Permalink to this headline">¬∂</a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¬∂</a></h2>
<p>As with configuring the subject list, pipeline configuration, and group analysis files, execute a C-PAC run by using C-PAC‚Äôs command line interface.</p>
<p>In addition to running C-PAC traditionally on your own local computer or on a server, there are three other avenues through which you can run C-PAC without going through the install process:</p>
<ul class="simple">
<li><p>With a Docker or Singularity container (optionally with <a class="reference internal" href="cpac"><span class="doc">a simple Python commandline interface</span></a>)</p></li>
<li><p>On the Amazon AWS Cloud</p></li>
<li><p>Through OpenNeuro</p></li>
</ul>
<p>More details of these options are available below.</p>
<p>If you re-run C-PAC with an output directory containing a working directory (from the runtime flag <code class="docutils literal notranslate"><span class="pre">--save_working_dir</span></code>), C-PAC will use that working directories contents in the re-run. If you try to re-run on an output directory with a saved working directory from a different version of C-PAC than the one that you‚Äôre currently running, differences in the working directory could cause problems.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>C-PAC migrated from Python 2 to Python 3 in v1.6.2 (see <a class="reference external" href="rnotes">release notes</a>). If your working directory contains Python 2 pickles from an older version of C-PAC and you want to continue to use this working directory, run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cpac</span> <span class="n">utils</span> <span class="n">repickle</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">working_dir</span>
</pre></div>
</div>
<p>or:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>docker run -i --rm --user $(id -u):$(id -g) -v /path/to/working_dir:/working fcpindi/c-pac:latest /bids_dir /outputs cli -- utils repickle /working
</pre></div>
</div>
<p>or:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">singularity</span> <span class="n">run</span> <span class="n">C</span><span class="o">-</span><span class="n">PAC_latest</span><span class="o">.</span><span class="n">sif</span> <span class="o">/</span><span class="n">bids_dir</span> <span class="o">/</span><span class="n">outputs</span> <span class="n">cli</span> <span class="o">--</span> <span class="n">utils</span> <span class="n">repickle</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">working_dir</span>
</pre></div>
</div>
<p>before running C-PAC ‚â• v1.6.2</p>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="help#working-dir-crashes"><span class="std std-ref">Common Issue: I‚Äôm re-running a pipeline, but I am receiving many crashes</span></a></p>
</div>
</section>
<section id="cpac-python-package">
<h2>cpac (Python package)<a class="headerlink" href="#cpac-python-package" title="Permalink to this headline">¬∂</a></h2>
<p><a class="reference external" href="https://pypi.org/project/cpac/">cpac</a> is available so that you can easily run analyses without needing interact with the container platform that allows you to run C-PAC without installing all of the underlying software.</p>
<p>cpac requires Python 3.6 or greater. To get cpac, simply</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">pip install cpac</span>
</pre></div>
</div>
<section id="download-upgrade-c-pac-with-cpac">
<h3>Download / Upgrade C-PAC with cpac<a class="headerlink" href="#download-upgrade-c-pac-with-cpac" title="Permalink to this headline">¬∂</a></h3>
<p>To download or upgrade a particular C-PAC image,</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cpac pull</span>
</pre></div>
</div>
<p>or</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cpac upgrade</span>
</pre></div>
</div>
<p>When downloading/upgrading, the <code class="docutils literal notranslate"><span class="pre">--platform</span></code>, <code class="docutils literal notranslate"><span class="pre">--image</span></code>, and <code class="docutils literal notranslate"><span class="pre">--tag</span></code> let you specify platform (Docker or Singularity), image (Docker image name or URL to image in repository), and tag (<a class="reference internal" href="versions"><span class="doc">version tag</span></a>), respectively.</p>
<p>For example, a development Docker image can be downloaded with</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cpac --platform docker --tag nightly pull</span>
</pre></div>
</div>
<p>Or a Singularity image built from that Docker image can be downloaded with</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cpac --platform singularity --tag nightly pull</span>
</pre></div>
</div>
</section>
<section id="run-c-pac-with-cpac">
<h3>Run C-PAC with cpac<a class="headerlink" href="#run-c-pac-with-cpac" title="Permalink to this headline">¬∂</a></h3>
<p>To run C-PAC in participant mode for one participant, using a BIDS dataset stored on your machine or server and using the container image‚Äôs default pipeline configuration:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cpac run /Users/You/local_bids_data /Users/You/some_folder_for_outputs participant</span>
</pre></div>
</div>
<p>By default, cpac (the wrapper) will try Docker first and fall back to Singularity if Docker fails. If both fail, an exception is raised.</p>
<p>You can specify a platform with the <code class="docutils literal notranslate"><span class="pre">--platform</span> <span class="pre">docker</span></code> or <code class="docutils literal notranslate"><span class="pre">--platform</span> <span class="pre">singularity</span></code>. If you specify a platform without specifying an image, these are the defaults, using the first successfully found image:</p>
</section>
<section id="usage">
<h3>Usage<a class="headerlink" href="#usage" title="Permalink to this headline">¬∂</a></h3>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>cpac<span class="w"> </span>--help

<span class="go">usage: cpac [-h] [--version] [-o OPT] [-B CUSTOM_BINDING]</span>
<span class="go">            [--platform {docker,singularity}] [--image IMAGE] [--tag TAG]</span>
<span class="go">            [--working_dir PATH] [-v] [-vv]</span>
<span class="go">            {run,utils,version,group,pull,upgrade,enter,bash,shell,parse-resources,parse_resources,crash}</span>
<span class="go">            ...</span>

<span class="go">cpac: a Python package that simplifies using C-PAC &lt;http://fcp-indi.github.io&gt; containerized images.</span>

<span class="go">This commandline interface package is designed to minimize repetition.</span>
<span class="go">As such, nearly all arguments are optional.</span>

<span class="go">When launching a container, this package will try to bind any paths mentioned in</span>
<span class="go"> ‚Ä¢ the command</span>
<span class="go"> ‚Ä¢ the data configuration</span>

<span class="go">An example minimal run command:</span>
<span class="go">     cpac run /path/to/data /path/for/outputs</span>

<span class="go">An example run command with optional arguments:</span>
<span class="go">     cpac -B /path/to/data/configs:/configs \</span>
<span class="go">             --image fcpindi/c-pac --tag latest \</span>
<span class="go">             run /path/to/data /path/for/outputs \</span>
<span class="go">             --data_config_file /configs/data_config.yml \</span>
<span class="go">             --save_working_dir</span>

<span class="go">Each command can take &quot;--help&quot; to provide additonal usage information, e.g.,</span>

<span class="go">     cpac run --help</span>

<span class="go">Known issues:</span>
<span class="go">- Some Docker containers unexpectedly persist after cpac finishes. To clear them, run</span>
<span class="go">    1. `docker ps` to list the containers</span>
<span class="go">  For each C-PAC conatainer that persists, run</span>
<span class="go">    2. `docker attach &lt;container_name&gt;`</span>
<span class="go">    3. `exit`</span>
<span class="go">- https://github.com/FCP-INDI/cpac/issues</span>

<span class="go">positional arguments:</span>
<span class="go">  {run,utils,version,group,pull,upgrade,enter,bash,shell,parse-resources,parse_resources,crash}</span>
<span class="go">    run                 Run C-PAC. See</span>
<span class="go">                        &quot;cpac [--platform {docker,singularity}] [--image IMAGE] [--tag TAG] run --help&quot;</span>
<span class="go">                        for more information.</span>
<span class="go">    utils               Run C-PAC commandline utilities. See</span>
<span class="go">                        &quot;cpac [--platform {docker,singularity}] [--image IMAGE] [--tag TAG] utils --help&quot;</span>
<span class="go">                        for more information.</span>
<span class="go">    version             Print the version of C-PAC that cpac is using.</span>
<span class="go">    group               Run a group level analysis in C-PAC. See</span>
<span class="go">                        &quot;cpac [--platform {docker,singularity}] [--image IMAGE] [--tag TAG] group --help&quot;</span>
<span class="go">                        for more information.</span>
<span class="go">    pull (upgrade)      Upgrade your local C-PAC version to the latest version</span>
<span class="go">                        by pulling from Docker Hub or other repository.</span>
<span class="go">                        Use with &quot;--image&quot; and/or &quot;--tag&quot; to specify an image</span>
<span class="go">                        other than the default &quot;fcpindi/c-pac:latest&quot; to pull.</span>
<span class="go">    enter (bash, shell)</span>
<span class="go">                        Enter a new C-PAC container via BASH.</span>
<span class="go">    parse-resources (parse_resources)</span>
<span class="go">                        When provided with a `callback.log` file, this utility can sort through</span>
<span class="go">                        the memory `runtime` usage, `estimate`, and associated `efficiency`, to</span>
<span class="go">                        identify the `n` tasks with the `highest` or `lowest` of each of these</span>
<span class="go">                        categories.</span>
<span class="go">                        &quot;parse-resources&quot; is intended to be run outside a C-PAC container.</span>
<span class="go">                        See &quot;cpac parse-resources --help&quot; for more information.</span>
<span class="go">    crash               Convert a crash pickle to plain text (C-PAC &lt; 1.8.0).</span>

<span class="go">optional arguments:</span>
<span class="go">  -h, --help            show this help message and exit</span>
<span class="go">  --version             show program&#39;s version number and exit</span>
<span class="go">  -o OPT, --container_option OPT</span>
<span class="go">                        parameters and flags to pass through to Docker or Singularity</span>

<span class="go">                        This flag can take multiple arguments so cannot be</span>
<span class="go">                        the final argument before the command argument (i.e.,</span>
<span class="go">                        run or any other command that does not start with - or --)</span>
<span class="go">  -B CUSTOM_BINDING, --custom_binding CUSTOM_BINDING</span>
<span class="go">                        directories to bind with a different path in</span>
<span class="go">                        the container than the real path of the directory.</span>
<span class="go">                        One or more pairs in the format:</span>
<span class="go">                             real_path:container_path</span>
<span class="go">                        (eg, /home/C-PAC/run5/outputs:/outputs).</span>
<span class="go">                        Use absolute paths for both paths.</span>

<span class="go">                        This flag can take multiple arguments so cannot be</span>
<span class="go">                        the final argument before the command argument (i.e.,</span>
<span class="go">                        run or any other command that does not start with - or --)</span>
<span class="go">  --platform {docker,singularity}</span>
<span class="go">                        If neither platform nor image is specified,</span>
<span class="go">                        cpac will try Docker first, then try</span>
<span class="go">                        Singularity if Docker fails.</span>
<span class="go">  --image IMAGE         path to Singularity image file OR name of Docker image (eg, &quot;fcpindi/c-pac&quot;).</span>
<span class="go">                        Will attempt to pull from Singularity Hub or Docker Hub if not provided.</span>
<span class="go">                        If image is specified but platform is not, platform is</span>
<span class="go">                        assumed to be Singularity if image is a path or</span>
<span class="go">                        Docker if image is an image name.</span>
<span class="go">  --tag TAG             tag of the Docker image to use (eg, &quot;latest&quot; or &quot;nightly&quot;).</span>
<span class="go">  --working_dir PATH    working directory</span>
<span class="go">  -v, --verbose         set loglevel to INFO</span>
<span class="go">  -vv, --very-verbose   set loglevel to DEBUG</span>
</pre></div>
</div>
<section id="platform-docker">
<h4><code class="docutils literal notranslate"><span class="pre">--platform</span> <span class="pre">docker</span></code><a class="headerlink" href="#platform-docker" title="Permalink to this headline">¬∂</a></h4>
<ul class="simple">
<li><p>Look for <code class="docutils literal notranslate"><span class="pre">fcpindi/c-pac:latest</span></code> locally.</p></li>
<li><p>Pull <code class="docutils literal notranslate"><span class="pre">fcpindi/c-pac:latest</span></code> from Docker Hub.</p></li>
</ul>
</section>
<section id="platform-singularity">
<h4><code class="docutils literal notranslate"><span class="pre">--platform</span> <span class="pre">singularity</span></code><a class="headerlink" href="#platform-singularity" title="Permalink to this headline">¬∂</a></h4>
<ul class="simple">
<li><p>Look in the present working directory for any Singularity images. If more than one is found, use the most recently modified.</p></li>
<li><p>Pull <code class="docutils literal notranslate"><span class="pre">FCP-INDI/C-PAC</span></code> from Singularity Hub.</p></li>
<li><p>Pull <code class="docutils literal notranslate"><span class="pre">fcpindi/c-pac:latest</span></code> from Docker Hub and convert to a Singularity image.</p></li>
</ul>
<p>You can also specify a container image with an <code class="docutils literal notranslate"><span class="pre">--image</span></code> argument, passing an image name (e.g., <code class="docutils literal notranslate"><span class="pre">fcpindi/c-pac</span></code>) for a Docker image or a filepath (e.g. <code class="docutils literal notranslate"><span class="pre">~/singularity_images/C-PAC.sif</span></code>) for a Singularity image. You can also specify a <code class="docutils literal notranslate"><span class="pre">--tag</span></code> (e.g., <code class="docutils literal notranslate"><span class="pre">latest</span></code> or <code class="docutils literal notranslate"><span class="pre">nightly</span></code>).</p>
<blockquote>
<div><div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="versions"><span class="doc">C-PAC versions</span></a></p>
</div>
</div></blockquote>
<p>You can also provide a link to an AWS S3 bucket containing a BIDS directory as the data source:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cpac run s3://fcp-indi/data/Projects/ADHD200/RawDataBIDS /Users/You/some_folder_for_outputs participant</span>
</pre></div>
</div>
<p>In addition to the default pipeline, C-PAC comes packaged with a growing library of pre-configured pipelines that are ready to use. To run C-PAC with one of the pre-packaged pre-configured pipelines, simply invoke the <code class="docutils literal notranslate"><span class="pre">--preconfig</span></code> flag, shown below. See the full selection of pre-configured pipelines <a class="reference internal" href="pipelines/preconfig"><span class="doc">here</span></a>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cpac run /Users/You/local_bids_data /Users/You/some_folder_for_outputs --preconfig anat-only</span>
</pre></div>
</div>
<p>To run C-PAC with a pipeline configuration file other than one of the pre-configured pipelines, assuming the configuration file is in the <code class="docutils literal notranslate"><span class="pre">/Users/You/Documents</span></code> directory:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cpac run /Users/You/local_bids_data /Users/You/some_folder_for_outputs participant --pipeline_file /Users/You/Documents/pipeline_config.yml</span>
</pre></div>
</div>
<p>Finally, to run C-PAC with a specific data configuration file (instead of providing a BIDS data directory):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cpac run /Users/You/any_directory /Users/You/some_folder_for_outputs participant --data_config_file /Users/You/Documents/data_config.yml</span>
</pre></div>
</div>
<p>Note: we are still providing the postionally-required <code class="docutils literal notranslate"><span class="pre">bids_dir</span></code> input parameter. However C-PAC will not look for data in this directory when you provide a data configuration YAML with the <code class="docutils literal notranslate"><span class="pre">--data_config_file</span></code> flag. Providing <code class="docutils literal notranslate"><span class="pre">.</span></code> or <code class="docutils literal notranslate"><span class="pre">$PWD</span></code> will simply pass the present working directory. In addition, if the dataset in your data configuration file is not in BIDS format, just make sure to add the <code class="docutils literal notranslate"><span class="pre">--skip_bids_validator</span></code> flag at the end of your command to bypass the BIDS validation process.</p>
<p>The full list of parameters and options that can be passed to C-PAC are shown below:</p>
</section>
</section>
<section id="usage-cpac-run">
<h3>Usage: cpac run<a class="headerlink" href="#usage-cpac-run" title="Permalink to this headline">¬∂</a></h3>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>cpac<span class="w"> </span>run<span class="w"> </span>--help

<span class="go">Loading üê≥ Docker</span>
<span class="go">Could not create /outputs/working. Binding /outputs/working to /home/circleci/build/outputs/working instead.</span>
<span class="go">Could not create /outputs/output. Binding /outputs/output to /home/circleci/build/outputs/output instead.</span>
<span class="go">Could not create /outputs/crash. Binding /outputs/crash to /home/circleci/build/outputs/crash instead.</span>
<span class="go">Could not create /outputs/logs. Binding /outputs/logs to /home/circleci/build/outputs/logs instead.</span>
<span class="go">Loading üê≥ fcpindi/c-pac:latest as &quot;circleci (1001)&quot; with these directory bindings:</span>
<span class="go">  local                                 Docker                mode</span>
<span class="go">  ------------------------------------  --------------------  ------</span>
<span class="go">  /etc/passwd                           /etc/passwd           ro</span>
<span class="go">  /home/circleci/.cpac                  /home/circleci/.cpac  rw</span>
<span class="go">  /home/circleci/build                  /home/circleci/build  rw</span>
<span class="go">  /home/circleci/build/outputs/working  /outputs/working      rw</span>
<span class="go">  /home/circleci/build/outputs/output   /outputs/output       rw</span>
<span class="go">  /home/circleci/build/outputs/crash    /outputs/crash        rw</span>
<span class="go">  /home/circleci/build/outputs/logs     /outputs/logs         rw</span>
<span class="go">Logging messages will refer to the Docker paths.</span>

<span class="go">usage: run.py [-h] [--pipeline_file PIPELINE_FILE] [--group_file GROUP_FILE]</span>
<span class="go">              [--data_config_file DATA_CONFIG_FILE] [--preconfig PRECONFIG]</span>
<span class="go">              [--aws_input_creds AWS_INPUT_CREDS]</span>
<span class="go">              [--aws_output_creds AWS_OUTPUT_CREDS] [--n_cpus N_CPUS]</span>
<span class="go">              [--mem_mb MEM_MB] [--mem_gb MEM_GB]</span>
<span class="go">              [--runtime_usage RUNTIME_USAGE]</span>
<span class="go">              [--runtime_buffer RUNTIME_BUFFER]</span>
<span class="go">              [--num_ants_threads NUM_ANTS_THREADS]</span>
<span class="go">              [--random_seed RANDOM_SEED]</span>
<span class="go">              [--save_working_dir [SAVE_WORKING_DIR]] [--disable_file_logging]</span>
<span class="go">              [--participant_label PARTICIPANT_LABEL [PARTICIPANT_LABEL ...]]</span>
<span class="go">              [--participant_ndx PARTICIPANT_NDX] [--T1w_label T1W_LABEL]</span>
<span class="go">              [--bold_label BOLD_LABEL [BOLD_LABEL ...]] [-v]</span>
<span class="go">              [--bids_validator_config BIDS_VALIDATOR_CONFIG]</span>
<span class="go">              [--skip_bids_validator] [--anat_only] [--tracking_opt-out]</span>
<span class="go">              [--monitoring]</span>
<span class="go">              bids_dir output_dir {participant,group,test_config,cli}</span>

<span class="go">C-PAC Pipeline Runner. Copyright (C) 2022 C-PAC Developers. This program comes</span>
<span class="go">with ABSOLUTELY NO WARRANTY. This is free software, and you are welcome to</span>
<span class="go">redistribute it under certain conditions. For details, see https://fcp-</span>
<span class="go">indi.github.io/docs/v1.8.4/license or the COPYING and COPYING.LESSER files</span>
<span class="go">included in the source code.</span>

<span class="go">positional arguments:</span>
<span class="go">  bids_dir              The directory with the input dataset formatted</span>
<span class="go">                        according to the BIDS standard. Use the format</span>
<span class="go">                        s3://bucket/path/to/bidsdir to read data directly from</span>
<span class="go">                        an S3 bucket. This may require AWS S3 credentials</span>
<span class="go">                        specified via the --aws_input_creds option.</span>
<span class="go">  output_dir            The directory where the output files should be stored.</span>
<span class="go">                        If you are running group level analysis this folder</span>
<span class="go">                        should be prepopulated with the results of the</span>
<span class="go">                        participant level analysis. Use the format</span>
<span class="go">                        s3://bucket/path/to/bidsdir to write data directly to</span>
<span class="go">                        an S3 bucket. This may require AWS S3 credentials</span>
<span class="go">                        specified via the --aws_output_creds option.</span>
<span class="go">  {participant,group,test_config,cli}</span>
<span class="go">                        Level of the analysis that will be performed. Multiple</span>
<span class="go">                        participant level analyses can be run independently</span>
<span class="go">                        (in parallel) using the same output_dir. test_config</span>
<span class="go">                        will run through the entire configuration process but</span>
<span class="go">                        will not execute the pipeline.</span>

<span class="go">optional arguments:</span>
<span class="go">  -h, --help            show this help message and exit</span>
<span class="go">  --pipeline_file PIPELINE_FILE</span>
<span class="go">                        Path for the pipeline configuration file to use. Use</span>
<span class="go">                        the format s3://bucket/path/to/pipeline_file to read</span>
<span class="go">                        data directly from an S3 bucket. This may require AWS</span>
<span class="go">                        S3 credentials specified via the --aws_input_creds</span>
<span class="go">                        option.</span>
<span class="go">  --group_file GROUP_FILE</span>
<span class="go">                        Path for the group analysis configuration file to use.</span>
<span class="go">                        Use the format s3://bucket/path/to/pipeline_file to</span>
<span class="go">                        read data directly from an S3 bucket. This may require</span>
<span class="go">                        AWS S3 credentials specified via the --aws_input_creds</span>
<span class="go">                        option. The output directory needs to refer to the</span>
<span class="go">                        output of a preprocessing individual pipeline.</span>
<span class="go">  --data_config_file DATA_CONFIG_FILE</span>
<span class="go">                        Yaml file containing the location of the data that is</span>
<span class="go">                        to be processed. This file is not necessary if the</span>
<span class="go">                        data in bids_dir is organized according to the BIDS</span>
<span class="go">                        format. This enables support for legacy data</span>
<span class="go">                        organization and cloud based storage. A bids_dir must</span>
<span class="go">                        still be specified when using this option, but its</span>
<span class="go">                        value will be ignored. Use the format</span>
<span class="go">                        s3://bucket/path/to/data_config_file to read data</span>
<span class="go">                        directly from an S3 bucket. This may require AWS S3</span>
<span class="go">                        credentials specified via the --aws_input_creds</span>
<span class="go">                        option.</span>
<span class="go">  --preconfig PRECONFIG</span>
<span class="go">                        Name of the preconfigured pipeline to run. Available</span>
<span class="go">                        preconfigured pipelines: [&#39;abcd-options&#39;, &#39;anat-only&#39;,</span>
<span class="go">                        &#39;benchmark-FNIRT&#39;, &#39;blank&#39;, &#39;ccs-options&#39;, &#39;fmriprep-</span>
<span class="go">                        options&#39;, &#39;fx-options&#39;, &#39;monkey&#39;, &#39;monkey-ABCD&#39;,</span>
<span class="go">                        &#39;ndmg&#39;, &#39;nhp-macaque&#39;, &#39;preproc&#39;, &#39;rbc-options&#39;,</span>
<span class="go">                        &#39;rodent&#39;]. See https://fcp-</span>
<span class="go">                        indi.github.io/docs/v1.8.4/user/pipelines/preconfig</span>
<span class="go">                        for more information about the preconfigured</span>
<span class="go">                        pipelines.</span>
<span class="go">  --aws_input_creds AWS_INPUT_CREDS</span>
<span class="go">                        Credentials for reading from S3. If not provided and</span>
<span class="go">                        s3 paths are specified in the data config we will try</span>
<span class="go">                        to access the bucket anonymously use the string &quot;env&quot;</span>
<span class="go">                        to indicate that input credentials should read from</span>
<span class="go">                        the environment. (E.g. when using AWS iam roles).</span>
<span class="go">  --aws_output_creds AWS_OUTPUT_CREDS</span>
<span class="go">                        Credentials for writing to S3. If not provided and s3</span>
<span class="go">                        paths are specified in the output directory we will</span>
<span class="go">                        try to access the bucket anonymously use the string</span>
<span class="go">                        &quot;env&quot; to indicate that output credentials should read</span>
<span class="go">                        from the environment. (E.g. when using AWS iam roles).</span>
<span class="go">  --n_cpus N_CPUS       Number of execution resources per participant</span>
<span class="go">                        available for the pipeline. This flag takes precidence</span>
<span class="go">                        over max_cores_per_participant in the pipeline</span>
<span class="go">                        configuration file.</span>
<span class="go">  --mem_mb MEM_MB       Amount of RAM available per participant in megabytes.</span>
<span class="go">                        Included for compatibility with BIDS-Apps standard,</span>
<span class="go">                        but mem_gb is preferred. This flag takes precedence</span>
<span class="go">                        over maximum_memory_per_participant in the pipeline</span>
<span class="go">                        configuration file.</span>
<span class="go">  --mem_gb MEM_GB       Amount of RAM available per participant in gigabytes.</span>
<span class="go">                        If this is specified along with mem_mb, this flag will</span>
<span class="go">                        take precedence. This flag also takes precedence over</span>
<span class="go">                        maximum_memory_per_participant in the pipeline</span>
<span class="go">                        configuration file.</span>
<span class="go">  --runtime_usage RUNTIME_USAGE</span>
<span class="go">                        Path to a callback.log from a prior run of the same</span>
<span class="go">                        pipeline configuration (including any resource-</span>
<span class="go">                        management parameters that will be applied in this</span>
<span class="go">                        run, like &#39;n_cpus&#39; and &#39;num_ants_threads&#39;). This log</span>
<span class="go">                        will be used to override per-node memory estimates</span>
<span class="go">                        with observed values plus a buffer.</span>
<span class="go">  --runtime_buffer RUNTIME_BUFFER</span>
<span class="go">                        Buffer to add to per-node memory estimates if</span>
<span class="go">                        --runtime_usage is specified. This number is a</span>
<span class="go">                        percentage of the observed memory usage.</span>
<span class="go">  --num_ants_threads NUM_ANTS_THREADS</span>
<span class="go">                        The number of cores to allocate to ANTS-based</span>
<span class="go">                        anatomical registration per participant. Multiple</span>
<span class="go">                        cores can greatly speed up this preprocessing step.</span>
<span class="go">                        This number cannot be greater than the number of cores</span>
<span class="go">                        per participant.</span>
<span class="go">  --random_seed RANDOM_SEED</span>
<span class="go">                        Random seed used to fix the state of execution. If</span>
<span class="go">                        unset, each process uses its own default. If set, a</span>
<span class="go">                        `random.log` file will be generated logging the random</span>
<span class="go">                        state used by each process. If set to a positive</span>
<span class="go">                        integer (up to 2147483647), that integer will be used</span>
<span class="go">                        to seed each process. If set to &#39;random&#39;, a random</span>
<span class="go">                        seed will be generated and recorded for each process.</span>
<span class="go">  --save_working_dir [SAVE_WORKING_DIR]</span>
<span class="go">                        Save the contents of the working directory.</span>
<span class="go">  --disable_file_logging</span>
<span class="go">                        Disable file logging, this is useful for clusters that</span>
<span class="go">                        have disabled file locking.</span>
<span class="go">  --participant_label PARTICIPANT_LABEL [PARTICIPANT_LABEL ...]</span>
<span class="go">                        The label of the participant that should be analyzed.</span>
<span class="go">                        The label corresponds to sub-&lt;participant_label&gt; from</span>
<span class="go">                        the BIDS spec (so it does not include &quot;sub-&quot;). If this</span>
<span class="go">                        parameter is not provided all participants should be</span>
<span class="go">                        analyzed. Multiple participants can be specified with</span>
<span class="go">                        a space separated list.</span>
<span class="go">  --participant_ndx PARTICIPANT_NDX</span>
<span class="go">                        The index of the participant that should be analyzed.</span>
<span class="go">                        This corresponds to the index of the participant in</span>
<span class="go">                        the data config file. This was added to make it easier</span>
<span class="go">                        to accommodate SGE array jobs. Only a single</span>
<span class="go">                        participant will be analyzed. Can be used with</span>
<span class="go">                        participant label, in which case it is the index into</span>
<span class="go">                        the list that follows the participant_label flag. Use</span>
<span class="go">                        the value &quot;-1&quot; to indicate that the participant index</span>
<span class="go">                        should be read from the AWS_BATCH_JOB_ARRAY_INDEX</span>
<span class="go">                        environment variable.</span>
<span class="go">  --T1w_label T1W_LABEL</span>
<span class="go">                        C-PAC only runs one T1w per participant-session at a</span>
<span class="go">                        time, at this time. Use this flag to specify any BIDS</span>
<span class="go">                        entity (e.g., &quot;acq-VNavNorm&quot;) or sequence of BIDS</span>
<span class="go">                        entities (e.g., &quot;acq-VNavNorm_run-1&quot;) to specify which</span>
<span class="go">                        of multiple T1w files to use. Specify &quot;--T1w_label</span>
<span class="go">                        T1w&quot; to choose the T1w file with the fewest BIDS</span>
<span class="go">                        entities (i.e., the final option of [*_acq-</span>
<span class="go">                        VNavNorm_T1w.nii.gz, *_acq-HCP_T1w.nii.gz,</span>
<span class="go">                        *_T1w.nii.gz&quot;]). C-PAC will choose the first T1w it</span>
<span class="go">                        finds if the user does not provide this flag, or if</span>
<span class="go">                        multiple T1w files match the --T1w_label provided. If</span>
<span class="go">                        multiple T2w files are present and a comparable filter</span>
<span class="go">                        is possible, T2w files will be filtered as well. If no</span>
<span class="go">                        T2w files match this --T1w_label, T2w files will be</span>
<span class="go">                        processed as if no --T1w_label were provided.</span>
<span class="go">  --bold_label BOLD_LABEL [BOLD_LABEL ...]</span>
<span class="go">                        To include a specified subset of available BOLD files,</span>
<span class="go">                        use this flag to specify any BIDS entity (e.g., &quot;task-</span>
<span class="go">                        rest&quot;) or sequence of BIDS entities (e.g. &quot;task-</span>
<span class="go">                        rest_run-1&quot;). To specify the bold file with the fewest</span>
<span class="go">                        BIDS entities in the file name, specify &quot;--bold_label</span>
<span class="go">                        bold&quot;. Multiple `--bold_label`s can be specified with</span>
<span class="go">                        a space-separated list. If multiple `--bold_label`s</span>
<span class="go">                        are provided (e.g., &quot;--bold_label task-rest_run-1</span>
<span class="go">                        task-rest_run-2&quot;, each scan that includes all BIDS</span>
<span class="go">                        entities specified in any of the provided</span>
<span class="go">                        `--bold_label`s will be analyzed. If this parameter is</span>
<span class="go">                        not provided all BOLD scans should be analyzed.</span>
<span class="go">  -v, --version         show program&#39;s version number and exit</span>
<span class="go">  --bids_validator_config BIDS_VALIDATOR_CONFIG</span>
<span class="go">                        JSON file specifying configuration of bids-validator:</span>
<span class="go">                        See https://github.com/bids-standard/bids-validator</span>
<span class="go">                        for more info.</span>
<span class="go">  --skip_bids_validator</span>
<span class="go">                        Skips bids validation.</span>
<span class="go">  --anat_only           run only the anatomical preprocessing</span>
<span class="go">  --tracking_opt-out    Disable usage tracking. Only the number of</span>
<span class="go">                        participants on the analysis is tracked.</span>
<span class="go">  --monitoring          Enable monitoring server on port 8080. You need to</span>
<span class="go">                        bind the port using the Docker flag &quot;-p&quot;.</span>
</pre></div>
</div>
</section>
<section id="usage-cpac-utils">
<h3>Usage: cpac utils<a class="headerlink" href="#usage-cpac-utils" title="Permalink to this headline">¬∂</a></h3>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>cpac<span class="w"> </span>utils<span class="w"> </span>--help

<span class="go">Loading üê≥ Docker</span>
<span class="go">Could not create /outputs/working. Binding /outputs/working to /home/circleci/build/outputs/working instead.</span>
<span class="go">Could not create /outputs/output. Binding /outputs/output to /home/circleci/build/outputs/output instead.</span>
<span class="go">Could not create /outputs/logs. Binding /outputs/logs to /home/circleci/build/outputs/logs instead.</span>
<span class="go">Could not create /outputs/crash. Binding /outputs/crash to /home/circleci/build/outputs/crash instead.</span>
<span class="go">Loading üê≥ fcpindi/c-pac:latest as &quot;circleci (1001)&quot; with these directory bindings:</span>
<span class="go">  local                                 Docker                mode</span>
<span class="go">  ------------------------------------  --------------------  ------</span>
<span class="go">  /etc/passwd                           /etc/passwd           ro</span>
<span class="go">  /home/circleci/.cpac                  /home/circleci/.cpac  rw</span>
<span class="go">  /home/circleci/build                  /home/circleci/build  rw</span>
<span class="go">  /home/circleci/build/outputs/working  /outputs/working      rw</span>
<span class="go">  /home/circleci/build/outputs/output   /outputs/output       rw</span>
<span class="go">  /home/circleci/build/outputs/logs     /outputs/logs         rw</span>
<span class="go">  /home/circleci/build/outputs/crash    /outputs/crash        rw</span>
<span class="go">Logging messages will refer to the Docker paths.</span>

<span class="go">Usage: run.py utils [OPTIONS] COMMAND [ARGS]...</span>

<span class="go">Options:</span>
<span class="go">  --help  Show this message and exit.</span>

<span class="go">Commands:</span>
<span class="go">  crash</span>
<span class="go">  data_config</span>
<span class="go">  group_config</span>
<span class="go">  pipe_config</span>
<span class="go">  repickle</span>
<span class="go">  test</span>
<span class="go">  tools</span>
<span class="go">  workflows</span>
</pre></div>
</div>
<p>Note that any of the optional arguments above will over-ride any pipeline settings in the default pipeline or in the pipeline configuration file you provide via the <code class="docutils literal notranslate"><span class="pre">--pipeline_file</span></code> parameter.</p>
<p><strong>Further usage notes:</strong></p>
<ul class="simple">
<li><p>You can run only anatomical preprocessing easily, without modifying your data or pipeline configuration files, by providing the <code class="docutils literal notranslate"><span class="pre">--anat_only</span></code> flag.</p></li>
<li><p>As stated, the default behavior is to read data that is organized in the BIDS format. This includes data that is in Amazon AWS S3 by using the format <code class="docutils literal notranslate"><span class="pre">s3://&lt;bucket_name&gt;/&lt;bids_dir&gt;</span></code> for the <code class="docutils literal notranslate"><span class="pre">bids_dir</span></code> command line argument. Outputs can be written to S3 using the same format for the <code class="docutils literal notranslate"><span class="pre">output_dir</span></code>. Credentials for accessing these buckets can be specified on the command line (using <code class="docutils literal notranslate"><span class="pre">--aws_input_creds</span></code> or <code class="docutils literal notranslate"><span class="pre">--aws_output_creds</span></code>).</p></li>
<li><p>When the app is run, a data configuration file is written to the working directory. This directory can be specified with <code class="docutils literal notranslate"><span class="pre">--working_dir</span></code> or the directory from which you run <code class="docutils literal notranslate"><span class="pre">cpac</span></code> will be used. This file can be passed into subsequent runs, which avoids the overhead of re-parsing the BIDS input directory on each run (i.e. for cluster or cloud runs). These files can be generated without executing the C-PAC pipeline using the <code class="docutils literal notranslate"><span class="pre">test_run</span></code> command line argument.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">participant_label</span></code> and <code class="docutils literal notranslate"><span class="pre">participant_ndx</span></code> arguments allow the user to specify which of the many datasets should be processed, which is useful when parallelizing the run of multiple participants.</p></li>
<li><p>If you want to pass runtime options to your container plaform (Docker or Singularity), you can pass them with <code class="docutils literal notranslate"><span class="pre">-o</span></code> or <code class="docutils literal notranslate"><span class="pre">--container_options</span></code>.</p></li>
</ul>
</section>
</section>
<section id="on-the-aws-cloud">
<h2>On the AWS Cloud<a class="headerlink" href="#on-the-aws-cloud" title="Permalink to this headline">¬∂</a></h2>
<p>The C-PAC team has released an Amazon Marketplace AMI, making it easier for researchers to use C-PAC in the cloud.  You can use the AMI to either launch a single machine for basic runs or create a high performance computing (HPC) cluster using Starcluster.  Clusters can be dynamically scaled up as your computational needs increase.  Detailed explanations of cloud computing and HPC are beyond the scope of this documentation, but we will define a few key terms before we start.  If these terms are familiar, you may skip them and proceed to later sections.</p>
<ul class="simple">
<li><p><strong>Amazon Machine Instance (AMI)</strong> - A disk image of an operating system and any additional installed software that can be used to create a virtual machine.</p></li>
<li><p><strong>Instance</strong> - A single running virtual machine whose initial state is based on the AMI that it is launched from.  Instances can be classified as spot instances or on-demand instances.  On-demand instances are reliably created the moment they are requested for a fixed rate.  Spot instances are created based on whether or not a bid that you set is accepted by Amazon.  They can be significantly cheaper than on-demand instances, but are only created when Amazon accepts your bid.</p></li>
<li><p><strong>Instance Type</strong> - The hardware specification for a given instance. A list of the instance types made available by Amazon may be found <a class="reference external" href="http://aws.amazon.com/ec2/instance-types">here</a>.</p></li>
<li><p><strong>Terminated Instance</strong> - An instance is considered terminated when its resources have been completely freed up for use by others in the Amazon cloud.  Any data on a terminated instance that is not relocated to persistent storage such as EBS (see below) will be completely discarded.  Instance termination is the virtual equivalent of throwing out a physical server.  When you have terminated an instance, you are no longer paying for it.  Note that by default, instances do not have persistent storage attached to them- you will need to configure persistent storage when you set up the instance.</p></li>
<li><p><strong>Stopped Instance</strong> - An instance is considered stopped when it is not active, but its resources are still available for future use whenever you choose to reactivate it.  Stopping an instance is the virtual equivalent of turning a computer off or putting it in hibernate mode.  When you stop an instance, you continue to pay for the storage associated with it (i.e., the main and other volumes attached to it), but not for the instance itself.  You should stop an instance when the analyses you are working on are not fully done and you would like to preserve the current state of a running instance.</p></li>
<li><p><strong>Simple Storage Service (S3)</strong> - A form of storage offered by Amazon.  S3 is not intended to be directly attached to instances since it lacks a filesystem, but it can be used to archive large datasets.  Amazon provides tools for uploading data to S3 ‚Äòbuckets‚Äô where it can be stored.  It is less costly than EBS.</p></li>
<li><p><strong>Elastic Block Storage (EBS)</strong> - A form of persistent storage offered by Amazon for use with instances.  When you have terminated an instance, items stored in an EBS volume can be accessed by any future instances that you start up.</p></li>
<li><p><strong>EC2 Instance Store</strong> - A form of temporary storage that comes included with some instance types.  Instance store volumes must be added manually before launching an instance, and all files stored on them will be lost when the instance is terminated.  The instance store is typically mounted at <code class="docutils literal notranslate"><span class="pre">/mnt</span></code>.</p></li>
</ul>
<p>Lastly, it would be important to review any terms related to <a class="reference internal" href="compute_config"><span class="doc">the Sun Grid Engine job scheduler</span></a>.</p>
<p>Before you can create a single C-PAC machine or a C-PAC HPC cluster, you must first generate credentials that will allow you to log into any AWS instance that you create.  The following steps will walk you through the process of creating all the necessary credentials and encryption keys that you will need.</p>
<ol class="arabic simple">
<li><p>Go to <a class="reference external" href="http://aws.amazon.com/console/">http://aws.amazon.com/console/</a></p></li>
<li><p>Click the <cite>Sign in to the AWS Console</cite> button</p></li>
<li><p>Enter your e-mail address and password.  If you do not already have an account, enter your e-mail address, select <cite>I am a new user.</cite> and click the <cite>Sign in</cite> button.  Provide Amazon with the information (e-mail address, payment method) needed to create your account.</p></li>
<li><p>Amazon has different regions that it hosts its web services from (e.g. Oregon, Northern Virginia, Tokyo). In the upper right-hand corner there will be a region that you are logged into next to your user name. Change this to your preferred region.  The Marketplace AMI is available in all regions, although public AMIs (non-Marketplace AMIs shared from personal accounts) may not be.</p></li>
<li><p>Click on your name in the upper right corner and navigate to <cite>Security Credentials</cite>.  Accept the disclaimer that appears on the page.</p></li>
<li><p>Click on <cite>Access Keys</cite> and click on the blue <cite>Create New Access Key</cite> button.  Click <cite>Download Key File</cite> and move the resulting csv file to a safe and memorable location on your hard drive.</p></li>
<li><p>Click on the box in the upper left corner of AWS.  Click on <cite>EC2</cite>.  Click on <cite>Key Pairs</cite> in the left-hand column.</p></li>
<li><p>Click on the blue <cite>Create Key Pair</cite> button. Give your key an appropriate name and click on the blue <cite>Create</cite> button.  A .pem file will now save to disk.  Move this file to a safe and memorable location on your hard drive.</p></li>
<li><p>On your local drive, open a terminal and run the following command: <code class="docutils literal notranslate"><span class="pre">chmod</span> <span class="pre">400</span> <span class="pre">/path/to/pem/file</span></code></p></li>
</ol>
<p>Now that you have generated the access keys and a pem file, you may launch a single instance via Amazon‚Äôs web interface by following the steps below.  If you are planning on processing many subjects or obtaining computationally-intensive derivatives (such as network centrality), you should use Starcluster instead.</p>
<ol class="arabic simple">
<li><p>In the left-hand column under the <cite>INSTANCES</cite> header in the AWS console, click <cite>Instances</cite>. This is a dashboard of all instances you currently have running in the AWS cloud. Click the blue <cite>Launch Instance</cite> button.</p></li>
<li><p>On the left-hand side of the new page, click on the <cite>Amazon Marketplace</cite> tab and search <cite>c-pac</cite> in the search text box.</p></li>
<li><p>Click the blue <cite>Select</cite> button next to the C-PAC AMI.  Click the blue <cite>Continue</cite> button on the next screen.</p></li>
<li><p>Now choose the instance type that you would like to use.  Note that C-PAC requires at least 8 GB of RAM- the m3.xlarge instance type has 15 GB of RAM and 4 CPUs and functions well with C-PAC for small runs and experimentation.  This instance type is equivalent to a standard desktop machine in terms of processing power. To select this type, click on the <cite>General purpose</cite> tab and click the box next to <cite>m3.xlarge</cite>.  Then, click the <cite>Next: Configure Instance Details</cite> button.  Note that for most larger runs you will want to choose a more powerful instance type, such as c3.4xlarge or c3.8xlarge.</p></li>
<li><p>The details page can be used to request spot instances, as well as other functionality (including VPN, VPC options). For a basic run you do not need to change anything, although you can tailor it according to your future needs. Hovering over the ‚Äòi‚Äô icons on this page will give you more insight into the options available.  When done, click <cite>Next: Add Storage.</cite></p></li>
<li><p>On the storage page, you can allocate space for the workstation, such as user and system directories.  This is where you can attach instance store volumes if your instance type comes with them.  To do this, click the <cite>Add New Volume</cite> button and select the instance store via the dropdown menu in the <cite>Type</cite> column.  You may need to do this multiple times if your instance comes with multiple instance stores.  If you want the files stored on the root volume to be kept after the instance is terminated, uncheck the box below the <cite>Delete on Termination</cite> column.  Note that persistent storage for the datasets can be allocated and attached as described in a later section. Click <cite>Next: Tag Instance</cite>.</p></li>
<li><p>On this page you can tag the instance with metadata (e.g., details related to the specific purpose for the instance).  Tags are key-value pairs, so any contextual data that can be encapsulated in this format can be saved. Click <cite>Next: Configure Security Group</cite>.</p></li>
<li><p>On this page, you can modify who has access to the instance. The AMI defaults allow remote access from anywhere. If you would like to customize security to allow only a certain set of IP addresses and users access to the instance, you can do so here. If you find that custom settings, such as using the <cite>My IP</cite> setting or specifying a range of IP addresses, do not work, consult with your institution‚Äôs network administrator to make sure that you are entering settings correctly.  Click <cite>Review and Launch</cite> when you are done.</p></li>
<li><p>This final page summarizes the instance details you are about to launch. You might receive some warnings as a result of security or the instance type not being in the free tier.  These warnings can be ignored.</p></li>
<li><p>Click the <cite>Launch</cite> button. A dialogue box will ask you to choose a key pair for the instance. Every instance requires a key pair in order for you to securely log in and use it. Change the top drop down menu bar to <cite>Choose an existing key pair</cite> and select the key pair you created in the <cite>Creating AWS Access and Network Keys</cite> section in the other drop down menu.  Check the acknowledgement check box and click the blue <cite>Launch Instances</cite> button.</p></li>
<li><p>You can click the <cite>View Instances</cite> blue button on the lower right of the page after to watch your new instance start up in the instance console.</p></li>
<li><p>When the <cite>Instance State</cite> column reads <cite>running</cite> and the <cite>Status Checks</cite> column reads <cite>2/2</cite>, the instance should be active. Click on the row for the new instance.  In the bottom pane, take note of the values for the <cite>Instance ID</cite>, <cite>Public DNS</cite>, and <cite>Availability zone</cite> fields under the <cite>Description</cite> tab.</p></li>
</ol>
<ol class="arabic simple">
<li><p>Once your instance is up and running, you can create a persistent storage volume for your data and results.  In the left-hand column under the <cite>ELASTIC BLOCK STORE</cite> header in the AWS console, click <cite>Volumes</cite>. This is a dashboard of all volumes that you currently have stored in EBS. Click the blue <cite>Create Volume</cite> button.</p></li>
<li><p>Change the size field in the proceeding dialogue to have enough space to encompass the amount of data you expect to store.  A single volume can be as small as 1 GB or as large as 16 TB.  Change the availability zone to match the zone from your instance‚Äôs <cite>Description</cite> tab.</p></li>
<li><p>Click the checkbox next to the newly-created volume.  Click <cite>Actions</cite> followed by <cite>Attach Volumes</cite>.  Enter the <cite>Instance ID</cite> from the instance‚Äôs <cite>Description</cite> tab in the <cite>Instance</cite> field.  The <cite>Device</cite> field should fill itself automatically and should be of the form <cite>/dev/sdb</cite> or similar.  Note the letter used after the <cite>sd</cite>.  Click the blue <cite>Attach</cite> button.</p></li>
<li><p>Execute the following command from the terminal to make it so that your instance can see the volume (replace the letter <cite>b</cite> at the end of <cite>/dev/xvdb</cite> with the letter from the previous step).</p></li>
</ol>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">ssh -i /path/to/pem/file ubuntu@&lt;Public Domain Name&gt; &#39;sudo mkfs -t ext4 /dev/xvdb &amp;&amp; sudo mount /dev/xvdb /media/ebs</span>
</pre></div>
</div>
<p>To use this volume with future instances, you may attach it to the instance using the AWS console and then use this command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">ssh -i /path/to/pem/file ubuntu@&lt;Public Domain Name&gt; &#39;sudo mount /dev/xvdb /media/ebs&#39;</span>
</pre></div>
</div>
<p>Note that the creation of a persistent volume is heavily automated in Starcluster, so if you will be creating many different persistent volumes you should use Starcluster instead.</p>
<p>There are now two different means of accessing the instance.  Either through X2Go (a desktop GUI-based session) or through ssh (a command line session).</p>
<ol class="arabic simple">
<li><p>Open a terminal and type <code class="docutils literal notranslate"><span class="pre">ssh</span> <span class="pre">-i</span> <span class="pre">/path/to/pem/file</span> <span class="pre">ubuntu&#64;&lt;Public</span> <span class="pre">Domain</span> <span class="pre">Name&gt;</span></code>.</p></li>
<li><p>Type <cite>yes</cite> when asked if you trust the source.</p></li>
</ol>
<ol class="arabic simple">
<li><p>Install the X2Go client using the instructions <a class="reference external" href="http://wiki.x2go.org/doku.php/doc:installation:x2goclient">here</a>.</p></li>
<li><p>Open X2go and create a new session.</p></li>
<li><p>For <cite>Host:</cite>, enter the Public DNS from earlier.</p></li>
<li><p>For <cite>Login:</cite> enter <cite>ubuntu</cite>.</p></li>
<li><p><cite>SSH port:</cite> should be <cite>22</cite>.</p></li>
<li><p>For <cite>Use RSA/DSA key for ssh connection:</cite>, select the key you generated for the instance.</p></li>
<li><p>Select <cite>LXDE</cite> for <cite>Session</cite> and click <cite>OK</cite>.</p></li>
</ol>
<p>When you are done, your session configuration should look similar to the following:</p>
<figure class="align-default">
<img alt="../_images/cloud_x2go.png" src="../_images/cloud_x2go.png" />
</figure>
<p>Note: If X2Go does not work on your computer, you can add the <code class="docutils literal notranslate"><span class="pre">-X</span></code> flag to the ssh command to enable X11 port forwarding (i.e., the ssh command would be <code class="docutils literal notranslate"><span class="pre">ssh</span> <span class="pre">-X</span> <span class="pre">-i</span> <span class="pre">/path/to/pem/file</span> <span class="pre">ubuntu&#64;&lt;Public</span> <span class="pre">Domain</span> <span class="pre">Name&gt;</span></code>).  X11 port forwarding is very slow compared to X2Go, however, so it is recommended that you troubleshoot X2Go further before turning to this option.</p>
<p>To upload data to your newly-created AWS instance, you can run the following command on the computer containing your data:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">scp -r -i /path/to/pem/key /path/to/data ubuntu@&lt;Public Domain Name&gt;:/path/to/server/directory</span>
</pre></div>
</div>
<p>If you have configured persistent storage, you will want to ensure that <cite>/path/to/server/directory</cite> is pointing to the mount point for the persistent storage.  If you followed the instructions above or the instructions in the Starcluster section below, the mount point should be <cite>/media/ebs</cite>.</p>
<p>Starcluster is suggested for more sophisticated C-PAC runs.  Using Starcluster, you can parallelize your analyses by distributing subjects across multiple nodes in an HPC cluster.  The following section describes how to install and configure Starcluster to work with C-PAC, dynamically add nodes to your cluster and leverage C-PAC‚Äôs grid functionality.</p>
<p>If you have pip installed, Starcluster can be installed via:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">pip install starcluster</span>
</pre></div>
</div>
<p>Note that if you are using a *nix-based OS and you are not using an environment such as Miniconda, you will need to run the above command with <code class="docutils literal notranslate"><span class="pre">sudo</span></code>.</p>
<p>If you do not have pip installed, see the <a class="reference external" href="http://star.mit.edu/cluster/docs/latest/installation.html">Official Starcluster Installation Instructions</a> for alternative installation methods.</p>
<p>The C-PAC Starcluster plug-ins configure the SGE environment that C-PAC uses and ensure that storage space is writable.  From the terminal, download the C-PAC Starcluster plug-ins and install them by running the following commands:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cd /tmp</span>
<span class="go">git clone https://github.com/FCP-INDI/CPAC_CLOUD</span>
<span class="go">cd CPAC_CLOUD/sc_plugins</span>
<span class="go">mv *.py ~/.starcluster/plugins</span>
</pre></div>
</div>
<p>Now you will need to create a Starcluster configuration file so that Starcluster can use your keys and know which instance types you would like to use.  To begin, type <code class="docutils literal notranslate"><span class="pre">starcluster</span> <span class="pre">help</span></code> and select option 2.</p>
<p>Fill in the AWS access keys from the CVS file that you created in the <cite>Creating AWS Access and Network Keys</cite> section:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">aws</span> <span class="n">info</span><span class="p">]</span>
<span class="n">AWS_ACCESS_KEY_ID</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">Your</span> <span class="n">Acces</span> <span class="n">Key</span><span class="o">&gt;</span>
<span class="n">AWS_SECRET_ACCESS_KEY</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">Your</span> <span class="n">Secret</span> <span class="n">Key</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>You do not need to define the <code class="docutils literal notranslate"><span class="pre">AWS_USER_ID</span></code> field unless you want to create custom AMIs based off the C-PAC AMI.  The public C-PAC AMI is available in us-east-1, so you should not change the value of <code class="docutils literal notranslate"><span class="pre">AWS_REGION_NAME</span></code>.</p>
<p>Point your key definition to the pem file you generated in the <cite>Creating AWS Access and Network Keys</cite> section:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">key</span> <span class="n">cpac_key</span><span class="p">]</span>
<span class="n">KEY_LOCATION</span><span class="o">=/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">pem</span><span class="o">/</span><span class="n">file</span>
</pre></div>
</div>
<p>Find the image ID for the C-PAC AMI by logging into the AWS Console using your favorite web browser.  Make sure that you are in the <cite>N. Virginia</cite> region.  Navigate to the EC2 service click <cite>Images</cite> -&gt; <cite>AMIs</cite>.  Then click <cite>Owned by Me</cite> in the upper left corner and switch it to <cite>Public images</cite>.  Search for ‚ÄòCPAC‚Äô.  Select the version of C-PAC that you wish to use and look in the lower pane for the <cite>AMI ID</cite> field.</p>
<p>Add the following cluster definition to your configuration file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">cluster</span> <span class="n">cpac_cluster</span><span class="p">]</span>
<span class="n">KEYNAME</span> <span class="o">=</span> <span class="n">cpac_key</span>
<span class="n">PLUGINS</span> <span class="o">=</span> <span class="n">cpac_sge</span><span class="p">,</span> <span class="n">mnt_config</span>
<span class="n">CLUSTER_SIZE</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">CLUSTER_SHELL</span> <span class="o">=</span> <span class="n">bash</span>
<span class="n">NODE_IMAGE_ID</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">Image</span> <span class="n">ID</span><span class="o">&gt;</span>
<span class="n">MASTER_INSTANCE_TYPE</span> <span class="o">=</span> <span class="n">t2</span><span class="o">.</span><span class="n">medium</span>
<span class="n">NODE_INSTANCE_TYPE</span> <span class="o">=</span> <span class="n">c3</span><span class="mf">.8</span><span class="n">xlarge</span>
</pre></div>
</div>
<p>You can customize this to have additional nodes or use different instance types as per your needs.  Note that you can always add nodes later using Starcluster from the command line.  If you wish to use spot instances rather than on-demand instances, then add the following line to the cluster definition:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">SPOT</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">bidding_price</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>Also add the following two plug-in definitions for the C-PAC Starcluster plug-ins:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">plugin</span> <span class="n">cpac_sge</span><span class="p">]</span>
<span class="n">setup_class</span> <span class="o">=</span> <span class="n">cpac_sge</span><span class="o">.</span><span class="n">PEInstaller</span>
<span class="n">pe_url</span> <span class="o">=</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">raw</span><span class="o">.</span><span class="n">githubusercontent</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">FCP</span><span class="o">-</span><span class="n">INDI</span><span class="o">/</span><span class="n">CPAC_CLOUD</span><span class="o">/</span><span class="n">master</span><span class="o">/</span><span class="n">mpi_smp</span><span class="o">.</span><span class="n">conf</span>

<span class="p">[</span><span class="n">plugin</span> <span class="n">mnt_config</span><span class="p">]</span>
<span class="n">setup_class</span> <span class="o">=</span> <span class="n">mnt_perm</span><span class="o">.</span><span class="n">MntPermissions</span>
</pre></div>
</div>
<p>By default, the cluster will have an EBS-backed root volume and, if available, an instance store volume mounted at <code class="docutils literal notranslate"><span class="pre">/mnt</span></code>.  Neither of these volumes are persistent and they will be destroyed when the cluster terminates. A shared directory mounted at <cite>/home</cite> on the head node can be used across nodes. If you need more storage than what is available on the head node or if you want to keep your data after the cluster is terminated, you will need to create a new volume that can be attached to all nodes in the cluster.  To do so, begin by creating an EBS-backed volume:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">starcluster createvolume --shutdown-volume-host &lt;volume_size_in_gigabytes&gt; &lt;region&gt; -I t2.micro -i &lt;Image ID&gt;</span>
</pre></div>
</div>
<p>Type <code class="docutils literal notranslate"><span class="pre">starcluster</span> <span class="pre">listvolumes</span></code> and get the <cite>volume-id</cite> for the volume that you just created.  Open up your Starcluster configuration file and add the following volume definition:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">volume</span> <span class="n">cpac_volume</span><span class="p">]</span>
<span class="n">VOLUME_ID</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">Volume</span> <span class="n">ID</span><span class="o">&gt;</span>
<span class="n">MOUNT_PATH</span> <span class="o">=</span> <span class="o">/</span><span class="n">media</span><span class="o">/</span><span class="n">ebs</span>
</pre></div>
</div>
<p>Append the following line to your <cite>cpac_cluster</cite> definition:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">VOLUMES</span> <span class="o">=</span> <span class="n">cpac_volume</span>
</pre></div>
</div>
<p>The <a class="reference external" href="http://star.mit.edu/cluster/docs/latest/manual/volumes.html">Starcluster documentation</a> explains how to perform other operations such as resizing and removing volumes.</p>
<p>To start up the head node on your C-PAC HPC cluster, use the following Starcluster command (with substitutions where necessary):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">starcluster start -c cpac_cluster &lt;cluster_name&gt;</span>
</pre></div>
</div>
<p>To add additional nodes to your C-PAC HPC cluster, use the following Starcluster command (with substitutions where necessary):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">starcluster addnode -n &lt;number_of_nodes_to_add&gt; &lt;cluster_name&gt;</span>
</pre></div>
</div>
<p>If you wish to access the head node, type the following command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">starcluster sshmaster -X -u ubuntu &lt;cluster_name&gt;</span>
</pre></div>
</div>
<p>If you only wish to access the command line interface, you may omit the <cite>-X</cite> flag:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">starcluster sshmaster -u ubuntu &lt;cluster_name&gt;</span>
</pre></div>
</div>
<p>You may also use the instructions for X2Go from the <cite>Starting a Single C-PAC Instance via the AWS Console</cite> section to access the head node via a graphical shell.  To do so, obtain the public DNS for the head node by typing <code class="docutils literal notranslate"><span class="pre">starcluster</span> <span class="pre">listclusters</span></code>.  The public DNS will be in the last column of the row labeled <cite>master</cite>.</p>
<p>C-PAC performs the heavy lifting of creating an SGE job submission script and submitting it to the SGE job scheduler seamlessly.</p>
<p><strong>Via the shell:</strong></p>
<ol class="arabic simple">
<li><p>Open your pipeline configuration YAML file in your preferred text editor.</p></li>
<li><p>Change the <code class="docutils literal notranslate"><span class="pre">runOnGrid</span></code> field to a value of <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p>Make sure that the <code class="docutils literal notranslate"><span class="pre">resourceManager</span></code> field is set to <code class="docutils literal notranslate"><span class="pre">SGE</span></code>.</p></li>
<li><p>Set the <code class="docutils literal notranslate"><span class="pre">parallelEnvironment</span></code> field to <code class="docutils literal notranslate"><span class="pre">mpi_smp</span></code>.</p></li>
<li><p>Execute the following command to run your pipeline.</p></li>
</ol>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cpac_run.py /path/to/pipeline_config.yml /path/to/CPAC_subject_list.yml</span>
</pre></div>
</div>
<p>Once you are done submitting the job, you can check its status by typing <code class="docutils literal notranslate"><span class="pre">qstat</span></code>.  This command will produce output that looks similar to the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">job</span><span class="o">-</span><span class="n">ID</span>  <span class="n">prior</span>   <span class="n">name</span>       <span class="n">user</span>         <span class="n">state</span> <span class="n">submit</span><span class="o">/</span><span class="n">start</span> <span class="n">at</span>     <span class="n">queue</span>                          <span class="n">slots</span> <span class="n">ja</span><span class="o">-</span><span class="n">task</span><span class="o">-</span><span class="n">ID</span>
<span class="o">-----------------------------------------------------------------------------------------------------------------</span>
      <span class="mi">1</span> <span class="mf">0.55500</span> <span class="n">submit_201</span> <span class="n">ubuntu</span>       <span class="n">r</span>     <span class="mi">06</span><span class="o">/</span><span class="mi">05</span><span class="o">/</span><span class="mi">2015</span> <span class="mi">20</span><span class="p">:</span><span class="mi">42</span><span class="p">:</span><span class="mi">13</span> <span class="nb">all</span><span class="o">.</span><span class="n">q</span><span class="nd">@master</span>                       <span class="mi">1</span> <span class="mi">1</span>
      <span class="mi">1</span> <span class="mf">0.55500</span> <span class="n">submit_201</span> <span class="n">ubuntu</span>       <span class="n">r</span>     <span class="mi">06</span><span class="o">/</span><span class="mi">05</span><span class="o">/</span><span class="mi">2015</span> <span class="mi">20</span><span class="p">:</span><span class="mi">42</span><span class="p">:</span><span class="mi">13</span> <span class="nb">all</span><span class="o">.</span><span class="n">q</span><span class="nd">@node001</span>                      <span class="mi">1</span> <span class="mi">2</span>
      <span class="mi">2</span> <span class="mf">0.55500</span> <span class="n">submit_201</span> <span class="n">ubuntu</span>       <span class="n">r</span>     <span class="mi">06</span><span class="o">/</span><span class="mi">05</span><span class="o">/</span><span class="mi">2015</span> <span class="mi">20</span><span class="p">:</span><span class="mi">42</span><span class="p">:</span><span class="mi">58</span> <span class="nb">all</span><span class="o">.</span><span class="n">q</span><span class="nd">@node002</span>                      <span class="mi">1</span> <span class="mi">1</span>
      <span class="mi">2</span> <span class="mf">0.00000</span> <span class="n">submit_201</span> <span class="n">ubuntu</span>       <span class="n">qw</span>    <span class="mi">06</span><span class="o">/</span><span class="mi">05</span><span class="o">/</span><span class="mi">2015</span> <span class="mi">20</span><span class="p">:</span><span class="mi">42</span><span class="p">:</span><span class="mi">47</span>                                    <span class="mi">1</span> <span class="mi">2</span>
</pre></div>
</div>
<p>The <cite>job-ID</cite> is a number assigned to your job when it is submitted to the scheduler.  The <cite>state</cite> of the job can be represented by one of several values: <cite>r</cite> means that the job is running, <cite>qw</cite> means that the job is queued and waiting, and <cite>E</cite> means that an error has occurred. The <cite>queue</cite> column indicates on which nodes of your cluster the C-PAC job is being executed.</p>
<p>If an error has occurred on any of the nodes while your pipeline executes, you should check the <cite>cluster_temp_files</cite> directory that was created in the directory from which you ran C-PAC.  This will contain copies of the job submission scripts that C-PAC generated to start your job.  It will also contain files containing the standard out and error messages for a given job.  You should check these first to determine what may have caused the error.  If these files do not help you determine what may have caused the error, feel free to ask for <a class="reference internal" href="help"><span class="doc">help</span></a> on the C-PAC forum.</p>
<p>When you are done and have exited from your cluster, the following command will terminate the cluster:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">starcluster terminate &lt;cluster_name&gt;</span>
</pre></div>
</div>
<p>If you receive an error from Starcluster while trying to terminate the instance, the following command will force Starcluster to terminate your cluster:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">starcluster terminate -f &lt;cluster_name&gt;</span>
</pre></div>
</div>
<p><strong>Warning:</strong> If you are not using persistent storage (see <cite>Attaching Persistent Storage to Your Cluster</cite>) then all of your data will be lost upon termination of the cluster.  You will need to copy your data to another drive if you wish to keep it.</p>
<ul class="simple">
<li><p><a class="reference external" href="http://star.mit.edu/cluster/docs/latest/manual/index.html">The StarCluster User Manual</a></p></li>
<li><p><a class="reference external" href="http://docs.aws.amazon.com/gettingstarted/latest/awsgsg-intro/gsg-aws-intro.html">Getting Started with AWS</a></p></li>
</ul>
</section>
<section id="with-openneuro">
<h2>With OpenNeuro<a class="headerlink" href="#with-openneuro" title="Permalink to this headline">¬∂</a></h2>
<p>The <a class="reference external" href="https://openneuro.org">OpenNeuro</a> project is an initiative to provide easy access to public neuroimaging datasets and the ability to quickly run analysis pipelines on these datasets directly through a web interface. C-PAC is available as an app on OpenNeuro, and more information on running apps on the platform is available <a class="reference external" href="https://openneuro.org/faq">here</a>.</p>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index">
              <img class="logo" src="../_static/cpac_logo_vertical.png" alt="Logo"/>
            </a></p>
  <h3><a href="../index">Table of Contents</a></h3>
  <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index">User Guide</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="quick">1. C-PAC Quickstart</a></li>
<li class="toctree-l2"><a class="reference internal" href="subject_list_config">2. Specify Your Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="pipelines/pipeline_config">3. Select Your Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing">4. Pre-Process Your Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="derivatives">5. Compute Derivatives</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">6. All Run Options</a></li>
<li class="toctree-l2"><a class="reference internal" href="group_analysis">7. Run Group Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="output_dir">8. Check Your Outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/index">9. Tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="help">10. Troubleshoot</a></li>
<li class="toctree-l2"><a class="reference internal" href="rnotes">11. Release Notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="appendix">Appendix</a></li>
<li class="toctree-l2"><a class="reference internal" href="appendix#benchmark-package">Benchmark Package</a></li>
<li class="toctree-l2"><a class="reference internal" href="versions">C-PAC versions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../developer/index">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license">License</a></li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="group_analysis" title="Group-Level Analysis"
             >next</a> |</li>
        <li class="right" >
          <a href="derivatives" title="Computable Derivatives"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index">C-PAC 1.8.5.dev1 Beta documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index" >User Documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Running C-PAC</a></li> 
      </ul>
    </div>

    <div class="footer" role="contentinfo">
        &#169; Copyright 2012‚Äí2022, C-PAC Developers. C-PAC is licensed under LGPL-3.0-or-later.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.0.0.
    </div>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-19224662-10"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-19224662-10');
    </script>
    <script defer src="https://fcp-indi.github.io/scripts/versionList.js"></script>

  </body>
</html>