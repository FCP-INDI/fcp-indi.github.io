
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>C-PAC Quickstart &#8212; C-PAC 1.3.0 Beta documentation</title>
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.3.0 Beta',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Installing C-PAC" href="install.html" />
    <link rel="prev" title="Welcome to C-PAC’s Documentation!" href="index.html" /> 
  </head>
  <body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="install.html" title="Installing C-PAC"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="index.html" title="Welcome to C-PAC’s Documentation!"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">C-PAC 1.3.0 Beta documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="c-pac-quickstart">
<h1>C-PAC Quickstart<a class="headerlink" href="#c-pac-quickstart" title="Permalink to this headline">¶</a></h1>
<div class="section" id="running-on-docker">
<h2>Running on Docker<a class="headerlink" href="#running-on-docker" title="Permalink to this headline">¶</a></h2>
<p>A C-PAC <a class="reference external" href="https://www.docker.com/">Docker image</a> is available so that you can easily get an analysis running without needing to install C-PAC.</p>
<p>The Docker image is designed following the specification established by the <a class="reference external" href="https://github.com/BIDS-Apps">BIDS-Apps project</a>, an initiative to create a collection of reproducible neuroimaging workflows that can be executed as self-contained environments using <a class="reference external" href="https://www.docker.com/">Docker</a> containers.  These workflows take as input any dataset that is organized according to the <a class="reference external" href="http://http://bids.neuroimaging.io">Brain Imaging Data Structure (BIDS) standard</a> and generating first-level outputs for this dataset. However, you can provide the C-PAC Docker image with a custom non-BIDS dataset by entering your own data configuration file. More details below.</p>
<p>In addition, we have created a Docker default pipeline configuration as part of this initiative that allows you to run the C-PAC pipeline on your data in an environment that is fully provisioned with all of C-PAC’s dependencies - more details about the default pipeline are available further below. If you wish to run your own pipeline configuration, you can also provide this to the Docker image at run-time.</p>
<p>To start, first pull the image from Docker Hub:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>docker pull fcpindi/c-pac:latest
</pre></div>
</div>
<p>Once this is complete, you can use the <code class="docutils literal"><span class="pre">fcpindi/c-pac</span></code> image tag to invoke runs. The full C-PAC Docker image usage options are shown here, with specific use cases further below.</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>usage: run.py <span class="o">[</span>-h<span class="o">]</span> <span class="o">[</span>--pipeline_file PIPELINE_FILE<span class="o">]</span>
              <span class="o">[</span>--data_config_file DATA_CONFIG_FILE<span class="o">]</span>
              <span class="o">[</span>--aws_input_creds AWS_INPUT_CREDS<span class="o">]</span>
              <span class="o">[</span>--aws_output_creds AWS_OUTPUT_CREDS<span class="o">]</span> <span class="o">[</span>--n_cpus N_CPUS<span class="o">]</span>
              <span class="o">[</span>--mem_mb MEM_MB<span class="o">]</span> <span class="o">[</span>--mem_gb MEM_GB<span class="o">]</span> <span class="o">[</span>--save_working_dir<span class="o">]</span>
              <span class="o">[</span>--participant_label PARTICIPANT_LABEL <span class="o">[</span>PARTICIPANT_LABEL ...<span class="o">]]</span>
              <span class="o">[</span>--participant_ndx PARTICIPANT_NDX<span class="o">]</span>
              bids_dir output_dir <span class="o">{</span>participant,group,test_config,GUI<span class="o">}</span>

C-PAC Pipeline Runner

positional arguments:
  bids_dir              The directory with the input dataset formatted
                        according to the BIDS standard. Use the format
                        s3://bucket/path/to/bidsdir to <span class="nb">read</span> data directly from
                        an S3 bucket. This may require AWS S3 credentials
                        specified via the --aws_input_creds option.
  output_dir            The directory where the output files should be stored.
                        If you are running group level analysis this folder
                        should be prepopulated with the results of the
                        participant level analysis. Us the format
                        s3://bucket/path/to/bidsdir to write data directly to
                        an S3 bucket. This may require AWS S3 credentials
                        specified via the --aws_output_creds option.
  <span class="o">{</span>participant,group,test_config,GUI<span class="o">}</span>
                        Level of the analysis that will be performed. Multiple
                        participant level analyses can be run independently
                        <span class="o">(</span>in parallel<span class="o">)</span> using the same output_dir. GUI will open
                        the CPAC gui <span class="o">(</span>currently only works with singularity<span class="o">)</span>
                        and test_config will run through the entire
                        configuration process but will not execute the
                        pipeline.

optional arguments:
  -h, --help            show this <span class="nb">help</span> message and <span class="nb">exit</span>
  --pipeline_file PIPELINE_FILE
                        Name <span class="k">for</span> the pipeline configuration file to use
  --data_config_file DATA_CONFIG_FILE
                        Yaml file containing the location of the data that is
                        to be processed. Can be generated from the CPAC gui.
                        This file is not necessary <span class="k">if</span> the data in bids_dir is
                        organized according to the BIDS format. This enables
                        support <span class="k">for</span> legacy data organization and cloud based
                        storage. A bids_dir must still be specified when using
                        this option, but its value will be ignored.
  --aws_input_creds AWS_INPUT_CREDS
                        Credentials <span class="k">for</span> reading from S3. If not provided and
                        s3 paths are specified in the data config we will try
                        to access the bucket anonymously
  --aws_output_creds AWS_OUTPUT_CREDS
                        Credentials <span class="k">for</span> writing to S3. If not provided and s3
                        paths are specified in the output directory we will
                        try to access the bucket anonymously
  --n_cpus N_CPUS       Number of execution resources available <span class="k">for</span> the
                        pipeline
  --mem_mb MEM_MB       Amount of RAM available to the pipeline in megabytes.
                        Included <span class="k">for</span> compatibility with BIDS-Apps standard,
                        but mem_gb is preferred
  --mem_gb MEM_GB       Amount of RAM available to the pipeline in gigabytes.
                        <span class="k">if</span> this is specified along with mem_mb, this flag will
                        take precedence.
  --save_working_dir    Save the contents of the working directory.
  --participant_label PARTICIPANT_LABEL <span class="o">[</span>PARTICIPANT_LABEL ...<span class="o">]</span>
                        The label of the participant that should be analyzed.
                        The label corresponds to sub-&lt;participant_label&gt; from
                        the BIDS spec <span class="o">(</span>so it does not include <span class="s2">&quot;sub-&quot;</span><span class="o">)</span>. If this
                        parameter is not provided all subjects should be
                        analyzed. Multiple participants can be specified with
                        a space separated list. To work correctly this should
                        come at the end of the <span class="nb">command</span> line
  --participant_ndx PARTICIPANT_NDX
                        The index of the participant that should be analyzed.
                        This corresponds to the index of the participant in
                        the subject list file. This was added to make it
                        easier to accomodate SGE array jobs. Only a single
                        participant will be analyzed. Can be used with
                        participant label, in which <span class="k">case</span> it is the index into
                        the list that follows the particpant_label flag.
</pre></div>
</div>
<p>Note that any of the optional arguments above will over-ride any pipeline settings in the default pipeline or in the pipeline configuration file you provide via the <code class="docutils literal"><span class="pre">--pipeline_file</span></code> parameter.</p>
<p>As an example, in order to run the C-PAC Docker container in participant mode, for one participant, using a BIDS dataset stored on your machine or server, and using the Docker image’s default pipeline configuration (broken into multiple lines for convenience):</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>docker run -i --rm <span class="se">\</span>
        -v /Users/You/local_bids_data:/bids_dataset <span class="se">\</span>
        -v /Users/You/some_folder:/outputs <span class="se">\</span>
        -v /tmp:/scratch <span class="se">\</span>
        fcpindi/c-pac:latest /bids_dataset /outputs participant
</pre></div>
</div>
<p>Note, the <code class="docutils literal"><span class="pre">-v</span></code> flags map your local filesystem locations to a “location” within the Docker image. (For example, the <code class="docutils literal"><span class="pre">/bids_dataset</span></code> and <code class="docutils literal"><span class="pre">/outputs</span></code> directories in the command above are arbitrary names). If you provided <code class="docutils literal"><span class="pre">/Users/You/local_bids_data</span></code> to the <code class="docutils literal"><span class="pre">bids_dir</span></code> input parameter, Docker would not be able to access or see that directory, so it needs to be mapped first. In this example, the local machine’s <code class="docutils literal"><span class="pre">/tmp</span></code> directory has been mapped to the <code class="docutils literal"><span class="pre">/scratch</span></code> name because the C-PAC Docker image’s default pipeline sets the working directory to <code class="docutils literal"><span class="pre">/scratch</span></code>. If you wish to keep your working directory somewhere more permanent, you can simply map this like so: <code class="docutils literal"><span class="pre">-v</span> <span class="pre">/Users/You/working_dir:/scratch</span></code>.</p>
<p>To run the C-PAC Docker container with a pipeline configuration file other than the container’s default pipeline, assuming the configuration file is in the <code class="docutils literal"><span class="pre">/Users/You/Documents</span></code> directory:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>docker run -i --rm <span class="se">\</span>
        -v /Users/You/local_bids_data:/bids_dataset <span class="se">\</span>
        -v /Users/You/some_folder:/outputs <span class="se">\</span>
        -v /tmp:/scratch <span class="se">\</span>
        -v /Users/You/Documents:/configs <span class="se">\</span>
        -v /Users/You/resources:/resources <span class="se">\</span>
        fcpindi/c-pac:latest /bids_dataset /outputs participant --pipeline_file /configs/pipeline_config.yml
</pre></div>
</div>
<p>In this case, we need to map the directory containing the pipeline configuration file <code class="docutils literal"><span class="pre">/Users/You/Documents</span></code> to a Docker image virtual directory <code class="docutils literal"><span class="pre">/configs</span></code>. Note we are using this <code class="docutils literal"><span class="pre">/configs</span></code> directory in the <code class="docutils literal"><span class="pre">--pipeline_file</span></code> input flag. In addition, if there are any ROIs, masks, or input files listed in your pipeline configuration file, the directory these are in must be mapped as well- assuming <code class="docutils literal"><span class="pre">/Users/You/resources</span></code> is your directory of ROI and/or mask files, we map it with <code class="docutils literal"><span class="pre">-v</span> <span class="pre">/Users/You/resources:/resources</span></code>. In the pipeline configuration file you are providing, these ROI and mask files must be listed as <code class="docutils literal"><span class="pre">/resources/ROI.nii.gz</span></code> (etc.) because we have mapped <code class="docutils literal"><span class="pre">/Users/You/resources</span></code> to <code class="docutils literal"><span class="pre">/resources</span></code>.</p>
<p>Finally, to run the Docker container with a specific data configuration file (instead of providing a BIDS data directory):</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>docker run -i --rm <span class="se">\</span>
        -v /Users/You/any_directory:/bids_dataset <span class="se">\</span>
        -v /Users/You/some_folder:/outputs <span class="se">\</span>
        -v /tmp:/scratch <span class="se">\</span>
        -v /Users/You/Documents:/configs <span class="se">\</span>
        fcpindi/c-pac:latest /bids_dataset /outputs participant --data_config_file /configs/data_config.yml
</pre></div>
</div>
<p>Note: we are still providing <code class="docutils literal"><span class="pre">/bids_dataset</span></code> to the <code class="docutils literal"><span class="pre">bids_dir</span></code> input parameter. However, we have mapped this to any directory on your machine, as C-PAC will not look for data in this directory when you provide a data configuration YAML with the <code class="docutils literal"><span class="pre">--data_config_file</span></code> flag. In addition, if the dataset in your data configuration file is not in BIDS format, just make sure to add the <code class="docutils literal"><span class="pre">--skip_bids_validator</span></code> flag at the end of your command to bypass the BIDS validation process.</p>
<p><strong>Further usage notes:</strong></p>
<ul class="simple">
<li>A GUI can be invoked to assist in pipeline custimization by specifying the <code class="docutils literal"><span class="pre">GUI</span></code> command line argument, as opposed to <code class="docutils literal"><span class="pre">participant</span></code> (this currently only works for Singularity containers).</li>
<li>As stated, the default behavior is to read in data that is organized in the BIDS format. This includes data that is in Amazon AWS S3 by using the format <code class="docutils literal"><span class="pre">s3://&lt;bucket_name&gt;/&lt;bids_dir&gt;</span></code> for the <code class="docutils literal"><span class="pre">bids_dir</span></code> command line argument. Outputs can be written to S3 using the same format for the <code class="docutils literal"><span class="pre">output_dir</span></code>. Credentials for accessing these buckets can be specified on the command line (using <code class="docutils literal"><span class="pre">--aws_input_creds</span></code> or <code class="docutils literal"><span class="pre">--aws_output_creds</span></code>).</li>
<li>When the app is run, a data configuration file is written to the working directory. This file can be passed into subsequent runs, which avoids the overhead of re-parsing the BIDS input directory on each run (i.e. for cluster or cloud runs). These files can be generated without executing the C-PAC pipeline using the test_run command line argument.</li>
<li>The <code class="docutils literal"><span class="pre">participant_label</span></code> and <code class="docutils literal"><span class="pre">participant_ndx</span></code> arguments allow the user to specify which of the many datasets should be processed, which is useful when parallelizing the run of multiple participants.</li>
</ul>
</div>
<div class="section" id="run-the-gui">
<h2>Run the GUI<a class="headerlink" href="#run-the-gui" title="Permalink to this headline">¶</a></h2>
<p><strong>Running docker container on Linux</strong></p>
<p>Start the docker container, mapping the X socket (change /home to a local directory on your computer)</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>docker run -i --rm <span class="se">\</span>
    --privileged <span class="se">\</span>
    -e <span class="nv">DISPLAY</span><span class="o">=</span><span class="nv">$DISPLAY</span> <span class="se">\</span>
    -v /tmp/.X11-unix:/tmp/.X11-unix <span class="se">\</span>
    -v /tmp:/scratch <span class="se">\</span>
    -v /home/data/ds005:/bids_dataset <span class="se">\</span>
    -v /home/outputs:/outputs <span class="se">\</span>
    fcpindi/c-pac <span class="se">\</span>
    /bids_dataset /outputs GUI
</pre></div>
</div>
<p><strong>Running docker container on Mac OSX</strong></p>
<ol class="arabic simple">
<li><a class="reference external" href="https://www.xquartz.org">Install XQuartz</a></li>
<li>Start XQuartz (from terminal)</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre><span></span>open -a XQuartz
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li>Enable XQuartz connections from network clients</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre><span></span>XQuartz -&gt; preferences -&gt; security -&gt; <span class="s2">&quot;Allow connections from network clients&quot;</span>
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li>Get your ip address (e.g., might have to change eth0 to match the name of your network interface.)</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre><span></span><span class="nv">ip</span><span class="o">=</span><span class="k">$(</span>ifconfig en0 <span class="p">|</span> grep inet <span class="p">|</span> awk <span class="s1">&#39;$1==&quot;inet&quot; {print $2}&#39;</span><span class="k">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="5">
<li>Tell xhost to accept connections from the localhost</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre><span></span>xhost + <span class="si">${</span><span class="nv">ip</span><span class="si">}</span>
</pre></div>
</div>
<ol class="arabic simple" start="6">
<li>Start the docker container, mapping the X socket (change /home to a local directory on your computer)</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre><span></span>docker run -i --rm <span class="se">\</span>
    --privileged <span class="se">\</span>
    -e <span class="nv">DISPLAY</span><span class="o">=</span><span class="nv">$ip</span>:0 <span class="se">\</span>
    -v /tmp/.X11-unix:/tmp/.X11-unix <span class="se">\</span>
    -v /tmp:/scratch <span class="se">\</span>
    -v /home/data/ds005:/bids_dataset <span class="se">\</span>
    -v /home/outputs:/outputs <span class="se">\</span>
            fcpindi/c-pac <span class="se">\</span>
            /bids_dataset /outputs GUI
</pre></div>
</div>
<p><strong>Running singularity container GUI on Linux</strong></p>
<p>Start the docker container (it just works!, provided you change /home to a local directory on your computer)</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>singularity run <span class="se">\</span>
    -B /home/ubuntu:/mnt <span class="se">\</span>
    -B /mnt:/scratch <span class="se">\</span>
    -B /home/data/ds005:/bids_dataset <span class="se">\</span>
    -B /home/outputs:/outputs <span class="se">\</span>
    /home/ubuntu/workspace/container_build/singularity_images/cpac_latest.img <span class="se">\</span>
    /bids_dataset <span class="se">\</span>
    /outputs<span class="se">\</span>
    GUI
</pre></div>
</div>
<p>To convert the Docker container to a Singularity container :</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>docker run --privileged -ti --rm  <span class="se">\</span>
    -v /var/run/docker.sock:/var/run/docker.sock <span class="se">\</span>
    -v /home/srycajal/singularity_images:/output <span class="se">\</span>
    filo/docker2singularity <span class="se">\</span>
    bids/cpac
</pre></div>
</div>
<p>Example submit script for running as a Singularity container on sun grid engine:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span><span class="ch">#! /bin/bash</span>
<span class="c1">## SGE batch file - bgsp</span>
<span class="c1">#$ -S /bin/bash</span>
<span class="c1">## bgsp is the jobname and can be changed</span>
<span class="c1">#$ -N bgsp</span>
<span class="c1">## execute the job using the mpi_smp parallel enviroment and 8 cores per job</span>
<span class="c1">#$ -pe mpi_smp 8</span>
<span class="c1">## create an array of 1112 jobs</span>
<span class="c1">#$ -t 1-1112</span>
<span class="c1">#$ -V</span>
<span class="c1">## change the following working directory to a persistent directory that is</span>
<span class="c1">## available on all nodes, this is were messages printed by the app (stdout</span>
<span class="c1">## and stderr) will be stored</span>
<span class="c1">#$ -wd /home/ubuntu/workspace/cluster_files</span>

sudo chmod <span class="m">777</span> /mnt
mkdir -p /mnt/log/reports

<span class="nv">sge_ndx</span><span class="o">=</span><span class="k">$((</span> SGE_TASK_ID <span class="o">-</span> <span class="m">1</span> <span class="k">))</span>

<span class="c1"># random sleep so that jobs dont start at _exactly_ the same time</span>
sleep <span class="k">$((</span> <span class="nv">$SGE_TASK_ID</span> <span class="o">%</span> <span class="m">10</span> <span class="k">))</span>

singularity run -B /home/ubuntu:/mnt -B /mnt:/scratch <span class="se">\</span>
  /home/ubuntu/workspace/container_build/singularity_images/cpac_latest.img <span class="se">\</span>
  --n_cpus <span class="m">8</span> --mem <span class="m">12</span> <span class="se">\</span>
  --aws_input_creds /mnt/workspace/cluster_files/s3-keys.csv <span class="se">\</span>
  --aws_output_creds /mnt/workspace/cluster_files/s3-keys.csv <span class="se">\</span>
  --data_config_file /mnt/workspace/cluster_files/bgsp_data_config.yml <span class="se">\</span>
  s3://fcp-indi/data/Projects/BrainGenomicsSuperstructProject/orig_bids/ <span class="se">\</span>
  s3://fcp-indi/data/Projects/BrainGenomicsSuperstructProject/cpac_out/ <span class="se">\</span>
  participant --participant_ndx <span class="si">${</span><span class="nv">sge_ndx</span><span class="si">}</span>
</pre></div>
</div>
<p><strong>Notes:</strong></p>
<ul class="simple">
<li>With the exception of your home directory, which is mounted from the local filesystem, the filesystem in Singularity containers is read-only. Files can be easily transferred in and out of the container by mapping local directories to directories inside the container using the -B from:to command line argument, where the from dir is mapped to to. When using mapped directories, remember that the paths specified on the command line are in relation to the directory inside the container (e.g. the to directory).</li>
<li>Unless the <code class="docutils literal"><span class="pre">--save_working_dir</span></code> flag is set, the C-PAC app will use the <code class="docutils literal"><span class="pre">/scratch</span></code> directory for intermediary files. Since this directory is write protected, a directory from the local filesystem must be mapped to <code class="docutils literal"><span class="pre">/scratch</span></code> for the pipeline to run successfully. This directory should be large enough to hold all of the intermediary files for the datasets that are processed in parallel, as a rule of thumb we suggest 3 GB per dataset. Unless the <code class="docutils literal"><span class="pre">--save_working_dir</span></code> flag is set, the working directory will be deleted when the pipeline has completed.</li>
<li>Use the <code class="docutils literal"><span class="pre">--save_working_dir</span></code> flag to retain all intermediary files, which can be useful for debugging. In this case, the intermediary files will be saved in the working_dir subdirectory of the user specified output directory. This will require about 3GB per dataset, but may require more for multiple or very long fMRI scans.</li>
</ul>
<p><strong>Reporting errors and getting help</strong></p>
<p>Please report errors on the <a class="reference external" href="https://github.com/FCP-INDI/C-PAC/issues">C-PAC github page issue tracker</a>. Please use the <a class="reference external" href="https://groups.google.com/forum/#!forum/cpax_forum">C-PAC google group</a> for help using C-PAC and this application.</p>
</div>
<div class="section" id="default-pipeline">
<h2>Default Pipeline<a class="headerlink" href="#default-pipeline" title="Permalink to this headline">¶</a></h2>
<p>The default processing pipeline performs fMRI processing using four strategies, with and without global signal regression, with and without bandpass filtering.</p>
<p>Anatomical processing begins with conforming the data to RPI orientation and removing orientation header information that will interfere with further processing. A non-linear transform between skull-on images and a 2mm MNI brain-only template are calculated using ANTs [3]. Images are them skull-stripped using AFNI’s 3dSkullStrip [5] and subsequently segmented into WM, GM, and CSF using FSL’s fast tool [6]. The resulting WM mask was multiplied by a WM prior map that was transformed into individual space using the inverse of the linear transforms previously calculated during the ANTs procedure. A CSF mask was multiplied by a ventricle map derived from the Harvard-Oxford atlas distributed with FSL [4]. Skull-stripped images and grey matter tissue maps are written into MNI space at 2mm resolution.</p>
<p>Functional preprocessing begins with resampling the data to RPI orientation, and slice timing correction. Next, motion correction is performed using a two-stage approach in which the images are first coregistered to the mean fMRI and then a new mean is calculated and used as the target for a second coregistration (AFNI 3dvolreg [2]). A 7 degree of freedom linear transform between the mean fMRI and the structural image is calculated using FSL’s implementation of boundary-based registration [7]. Nuisance variable regression (NVR) is performed on motion corrected data using a 2nd order polynomial, a 24-regressor model of motion [8], 5 nuisance signals, identified via principal components analysis of signals obtained from white matter (CompCor, [9]), and mean CSF signal. WM and CSF signals were extracted using the previously described masks after transforming the fMRI data to match them in 2mm space using the inverse of the linear fMRI-sMRI transform. The NVR procedure is performed twice, with and without the inclusion of the global signal as a nuisance regressor. The residuals of the NVR procedure are processed with and without bandpass filtering (0.001Hz &lt; f &lt; 0.1Hz), written into MNI space at 3mm resolution and subsequently smoothed using a 6mm FWHM kernel.</p>
<p>Several different individual level analysis are performed on the fMRI data including:</p>
<ul class="simple">
<li><strong>Amplitude of low frequency fluctuations (alff) [10]:</strong> the variance of each voxel is calculated after bandpass filtering in original space and subsequently written into MNI space at 2mm resolution and spatially smoothed using a 6mm FWHM kernel.</li>
<li><strong>Fractional amplitude of low frequency fluctuations (falff) [11]:</strong> Similar to alff except that the variance of the bandpassed signal is divided by the total variance (variance of non-bandpassed signal.</li>
<li><strong>Regional homogeniety (ReHo) [12]:</strong> a simultaneous Kendalls correlation is calculated between each voxel’s time course and the time courses of the 27 voxels that are face, edge, and corner touching the voxel. ReHo is calculated in original space and subsequently written into MNI space at 2mm resolution and spatially smoothed using a 6mm FWHM kernel.</li>
<li><strong>Voxel mirrored homotopic connectivity (VMHC) [13]:</strong> an non-linear transform is calculated between the skull-on anatomical data and a symmetric brain template in 2mm space. Using this transform, processed fMRI data are written in to symmetric MNI space at 2mm and the correlation between each voxel and its analog in the contralateral hemisphere is calculated. The Fisher transform is applied to the resulting values, which are then spatially smoothed using a 6mm FWHM kernel.</li>
<li><strong>Weighted and binarized degree centrality (DC) [14]:</strong> fMRI data is written into MNI space at 2mm resolution and spatially smoothed using a 6mm FWHM kernel. The voxel x voxel similarity matrix is calculated by the correlation between every pair of voxel time courses and then thresholded so that only the top 5% of correlations remain. For each voxel, binarized DC is the number of connections that remain for the voxel after thresholding and weighted DC is the average correlation coefficient across the remaining connections.</li>
<li><strong>Eigenvector centrality (EC) [15]:</strong> fMRI data is written into MNI space at 2mm resolution and spatially smoothed using a 6mm FWHM kernel. The voxel x voxel similarity matrix is calculated by the correlation between every pair of voxel time courses and then thresholded so that only the top 5% of correlations remain. Weighted EC is calculated from the eigenvector corresponding to the largest eigenvalue from an eigenvector decomposition of the resulting similarity. Binarized EC, is the first eigenvector of the similarity matrix after setting the non-zero values in the resulting matrix are set to 1.</li>
<li><strong>Local functional connectivity density (lFCD) [16]:</strong> fMRI data is written into MNI space at 2mm resolution and spatially smoothed using a 6mm FWHM kernel. For each voxel, lFCD corresponds to the number of contiguous voxels that are correlated with the voxel above 0.6 (r&gt;0.6). This is similar to degree centrality, except only voxels that it only includes the voxels that are directly connected to the seed voxel.</li>
<li><strong>10 intrinsic connectivity networks (ICNs) from dual regression [17]:</strong> a template including 10 ICNs from a meta-analysis of resting state and task fMRI data [18] is spatially regressed against the processed fMRI data in MNI space. The resulting time courses are entered into a multiple regression with the voxel data in original space to calculate individual representations of the 10 ICNs. The resulting networks are written into MNI space at 2mm and then spatially smoothed using a 6mm FWHM kernel.</li>
<li><strong>Seed correlation analysis (SCA):</strong> preprocessed fMRI data is to match template that includes 160 regions of interest defined from a meta-analysis of different task results [19]. A time series is calculated for each region from the mean of all intra-ROI voxel time series. A seperate functional connectivity map is calculated per ROI by correlating its time course with the time courses of every other voxel in the brain. Resulting values are Fisher transformed, written into MNI space at 2mm resolution, and then spatiall smoothed using a 6mm FWHM kernel.</li>
<li><strong>Time series extraction:</strong> similar the procedure used for time series analysis, the preprocessed functional data is written into MNI space at 2mm and then time series for the various atlases are extracted by averaging within region voxel time courses. This procedure was used to generate summary time series for the automated anatomic labelling atlas [20], Eickhoff-Zilles atlas [21], Harvard-Oxford atlas [22], Talaraich and Tournoux atlas [23], 200 and 400 regions from the spatially constrained clustering voxel timeseries [24], and 160 ROIs from a meta-analysis of task results [19]. Time series for 10 ICNs were extracted using spatial regression.</li>
</ul>
</div>
<div class="section" id="acknowledgments">
<h2>Acknowledgments<a class="headerlink" href="#acknowledgments" title="Permalink to this headline">¶</a></h2>
<p>We currently have a publication in preparation, in the meantime please cite our poster from INCF:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>Craddock C, Sikka S, Cheung B, Khanuja R, Ghosh SS, Yan C, Li Q, Lurie D, Vogelstein J, Burns R, Colcombe S,
Mennes M, Kelly C, Di Martino A, Castellanos FX and Milham M <span class="o">(</span>2013<span class="o">)</span>. Towards Automated Analysis of Connectomes:
The Configurable Pipeline <span class="k">for</span> the Analysis of Connectomes <span class="o">(</span>C-PAC<span class="o">)</span>. Front. Neuroinform. Conference Abstract:
Neuroinformatics 2013. doi:10.3389/conf.fninf.2013.09.00042

@ARTICLE<span class="o">{</span>cpac2013,
    <span class="nv">AUTHOR</span><span class="o">={</span>Craddock, Cameron  and  Sikka, Sharad  and  Cheung, Brian  and  Khanuja, Ranjeet  and  Ghosh, Satrajit S
        and Yan, Chaogan  and  Li, Qingyang  and  Lurie, Daniel  and  Vogelstein, Joshua  and  Burns, Randal  and
        Colcombe, Stanley  and  Mennes, Maarten  and  Kelly, Clare  and  Di Martino, Adriana  and  Castellanos,
        Francisco Xavier  and  Milham, Michael<span class="o">}</span>,
    <span class="nv">TITLE</span><span class="o">={</span>Towards Automated Analysis of Connectomes: The Configurable Pipeline <span class="k">for</span> the Analysis of Connectomes <span class="o">(</span>C-PAC<span class="o">)}</span>,
    <span class="nv">JOURNAL</span><span class="o">={</span>Frontiers in Neuroinformatics<span class="o">}</span>,
    <span class="nv">YEAR</span><span class="o">={</span>2013<span class="o">}</span>,
    <span class="nv">NUMBER</span><span class="o">={</span>42<span class="o">}</span>,
    <span class="nv">URL</span><span class="o">={</span>http://www.frontiersin.org/neuroinformatics/10.3389/conf.fninf.2013.09.00042/full<span class="o">}</span>,
    <span class="nv">DOI</span><span class="o">={</span>10.3389/conf.fninf.2013.09.00042<span class="o">}</span>,
    <span class="nv">ISSN</span><span class="o">={</span>1662-5196<span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li>Gorgolewski, K., Burns, C.D., Madison, C., Clark, D., Halchenko, Y.O., Waskom, M.L., Ghosh, S.S.: Nipype: A flexible, lightweight and extensible neuroimaging data processing framework in python. Front. Neuroinform. 5 (2011). doi:10.3389/fninf.2011.00013</li>
<li>Cox, R.W., Jesmanowicz, A.: Real-time 3d image registration for functional mri. Magn Reson Med 42(6), 1014–8 (1999)</li>
<li>Avants, B., Epstein, C., Grossman, M., Gee, J.: Symmetric diffeomorphic image registration with cross-correlation: Evaluating automated labeling of elderly and neurodegenerative brain. Medical Image Analysis 12(1), 26–41 (2008). doi:10.1016/j.media.2007.06.004</li>
<li>Smith, S.M., Jenkinson, M., Woolrich, M.W., Beckmann, C.F., Behrens, T.E.J., Johansen-Berg, H., Bannister, P.R., Luca, M.D., Drobnjak, I., Flitney, D.E., Niazy, R.K., Saunders, J., Vickers, J., Zhang, Y., Stefano, N.D., Brady, J.M., Matthews, P.M.: Advances in functional and structural mr image analysis and implementation as fsl. NeuroImage 23, 208–219 (2004). doi:10.1016/j.neuroimage.2004.07.051</li>
<li>Smith, S.M.: Fast robust automated brain extraction. Human Brain Mapping 17(3), 143–155 (2002). doi:10.1002/hbm.10062</li>
<li>Zhang, Y., Brady, M., Smith, S.: Segmentation of brain mr images through a hidden markov random field model and the expectation-maximization algorithm. IEEE Transactions on Medical Imaging 20(1), 45–57 (2001). doi:10.1109/42.906424</li>
<li>Greve, D.N., Fischl, B.: Accurate and robust brain image alignment using boundary-based registration. NeuroImage 48(1), 63–72 (2009). doi:10.1016/j.neuroimage.2009.06.060</li>
<li>Friston, K.J., Williams, S., Howard, R., Frackowiak, R.S., Turner, R.: Movement-related effects in fmri time-series. Magn Reson Med 35(3), 346–55 (1996)</li>
<li>Behzadi, Y., Restom, K., Liau, J., Liu, T.T.: A component based noise correction method (compcor) for bold and perfusion based fmri. NeuroImage 37(1), 90–101 (2007). doi:10.1016/j.neuroimage.2007.04.042</li>
<li>Zang, Y.-F., He, Y., Zhu, C.-Z., Cao, Q.-J., Sui, M.-Q., Liang, M., Tian, L.-X., et al. (2007). Altered baseline brain activity in children with ADHD revealed by resting-state functional MRI. Brain &amp; development, 29(2), 83–91.</li>
<li>Zou, Q.-H., Zhu, C.-Z., Yang, Y., Zuo, X.-N., Long, X.-Y., Cao, Q.-J., Wang, Y.-F., et al. (2008). An improved approach to detection of amplitude of low-frequency fluctuation (ALFF) for resting-state fMRI: Fractional ALFF. Journal of neuroscience methods, 172(1), 137–141.</li>
<li>Zang, Y., Jiang, T., Lu, Y., He, Y., Tian, L., 2004. Regional homogeneity approach to fMRI data analysis. Neuroimage 22, 394-400.</li>
<li>Stark, D. E., Margulies, D. S., Shehzad, Z. E., Reiss, P., Kelly, A. M. C., Uddin, L. Q., Gee, D. G., et al. (2008). Regional variation in interhemispheric coordination of intrinsic hemodynamic fluctuations. The Journal of Neuroscience, 28(51), 13754–13764.</li>
<li>Buckner RL, Sepulcre J, Talukdar T, Krienen FM, Liu H, Hedden T, Andrews-Hanna JR, Sperling RA, Johnson KA. 2009. Cortical hubs revealed by intrinsic functional connectivity: mapping, assessment of stability, and relation to Alzheimer’s disease. J Neurosci. 29:1860–1873.</li>
<li>Lohmann G, Margulies DS, Horstmann A, Pleger B, Lepsien J, Goldhahn D, Schloegl H, Stumvoll M, Villringer A, Turner R. 2010. Eigenvector centrality mapping for analyzing connectivity patterns in fMRI data of the human brain. PLoS One. 5:e10232</li>
<li>Tomasi D, Volkow ND. 2010. Functional connectivity density mapping. PNAS. 107(21):9885-9890.</li>
<li>C.F. Beckmann, C.E. Mackay, N. Filippini, and S.M. Smith. Group comparison of resting-state FMRI data using multi-subject ICA and dual regression. OHBM, 2009.</li>
<li>Smith, S. M., Fox, P. T., Miller, K. L., Glahn, D. C., Fox, P. M., Mackay, C. E., et al. (2009). Correspondence of the brain’s functional architecture during activation and rest. Proceedings of the National Academy of Sciences of the United States of America, 106(31), 13040–13045. doi:10.1073/pnas.0905267106</li>
<li>Dosenbach, N. U. F., Nardos, B., Cohen, A. L., Fair, D. a, Power, J. D., Church, J. a, … Schlaggar, B. L. (2010). Prediction of individual brain maturity using fMRI. Science (New York, N.Y.), 329(5997), 1358–61. <a class="reference external" href="http://doi.org/10.1126/science.1194144">http://doi.org/10.1126/science.1194144</a></li>
<li>Tzourio-Mazoyer, N., Landeau, B., Papathanassiou, D., Crivello, F., Etard, O., Delcroix, N., … Joliot, M. (2002). Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain. NeuroImage, 15(1), 273–89. <a class="reference external" href="http://doi.org/10.1006/nimg.2001.0978">http://doi.org/10.1006/nimg.2001.0978</a></li>
<li>Eickhoff, S. B., Stephan, K. E., Mohlberg, H., Grefkes, C., Fink, G. R., Amunts, K., &amp; Zilles, K. (2005). A new SPM toolbox for combining probabilistic cytoarchitectonic maps and functional imaging data. NeuroImage, 25(4), 1325–35. <a class="reference external" href="http://doi.org/10.1016/j.neuroimage.2004.12.034">http://doi.org/10.1016/j.neuroimage.2004.12.034</a></li>
<li>Harvard-Oxford cortical and subcortical structural atlases, <a class="reference external" href="http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Atlases">http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Atlases</a></li>
<li>Lancaster, J. L., Woldorff, M. G., Parsons, L. M., Liotti, M., Freitas, C. S., Rainey, L., … Fox, P. T. (2000). Automated Talairach atlas labels for functional brain mapping. Human Brain Mapping, 10(3), 120–31. Retrieved from <a class="reference external" href="http://www.ncbi.nlm.nih.gov/pubmed/10912591">http://www.ncbi.nlm.nih.gov/pubmed/10912591</a></li>
<li>Craddock, R. C., James, G. A., Holtzheimer, P. E., Hu, X. P., &amp; Mayberg, H. S. (2011). A whole brain fMRI atlas generated via spatially constrained spectral clustering. Human Brain Mapping, 0(July 2010). <a class="reference external" href="http://doi.org/10.1002/hbm.21333">http://doi.org/10.1002/hbm.21333</a></li>
</ol>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/cpac_logo_vertical.png" alt="Logo"/>
            </a></p>
<h3><a href="index.html">Table Of Contents</a></h3>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">1. C-PAC Quickstart</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#running-on-docker">Running on Docker</a></li>
<li class="toctree-l2"><a class="reference internal" href="#run-the-gui">Run the GUI</a></li>
<li class="toctree-l2"><a class="reference internal" href="#default-pipeline">Default Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="install.html">2. Install C-PAC</a></li>
<li class="toctree-l1"><a class="reference internal" href="subject_list_config.html">3. Specify Your Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline_config.html">4. Select Your Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="running.html">5. Run C-PAC</a></li>
<li class="toctree-l1"><a class="reference internal" href="preprocessing.html">6. Pre-Process Your Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="derivatives.html">7. Compute Derivatives</a></li>
<li class="toctree-l1"><a class="reference internal" href="running.html">8. Run C-PAC</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_analysis.html">9. Run Group Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="output_dir.html">10. Check Your Outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="help.html">11. Troubleshoot</a></li>
<li class="toctree-l1"><a class="reference internal" href="rnotes.html">12. Release Notes</a></li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="install.html" title="Installing C-PAC"
             >next</a> |</li>
        <li class="right" >
          <a href="index.html" title="Welcome to C-PAC’s Documentation!"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">C-PAC 1.3.0 Beta documentation</a> &#187;</li> 
      </ul>
    </div>

    <div class="footer" role="contentinfo">
        &#169; Copyright 2018, C-PAC Team.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.3.
    </div>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-19224662-10"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-19224662-10');
    </script>

  </body>
</html>